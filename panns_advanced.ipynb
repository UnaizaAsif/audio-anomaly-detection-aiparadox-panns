{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117422,"databundleVersionId":14072840,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-15T10:13:38.752441Z","iopub.execute_input":"2025-10-15T10:13:38.752960Z","iopub.status.idle":"2025-10-15T10:13:39.903688Z","shell.execute_reply.started":"2025-10-15T10:13:38.752939Z","shell.execute_reply":"2025-10-15T10:13:39.902734Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ai-paradox/sample_submission.csv\n/kaggle/input/ai-paradox/test/00025.wav\n/kaggle/input/ai-paradox/test/00131.wav\n/kaggle/input/ai-paradox/test/00094.wav\n/kaggle/input/ai-paradox/test/00107.wav\n/kaggle/input/ai-paradox/test/00015.wav\n/kaggle/input/ai-paradox/test/00120.wav\n/kaggle/input/ai-paradox/test/00061.wav\n/kaggle/input/ai-paradox/test/00090.wav\n/kaggle/input/ai-paradox/test/00116.wav\n/kaggle/input/ai-paradox/test/00055.wav\n/kaggle/input/ai-paradox/test/00024.wav\n/kaggle/input/ai-paradox/test/00045.wav\n/kaggle/input/ai-paradox/test/00043.wav\n/kaggle/input/ai-paradox/test/00113.wav\n/kaggle/input/ai-paradox/test/00097.wav\n/kaggle/input/ai-paradox/test/00058.wav\n/kaggle/input/ai-paradox/test/00020.wav\n/kaggle/input/ai-paradox/test/00144.wav\n/kaggle/input/ai-paradox/test/00099.wav\n/kaggle/input/ai-paradox/test/00052.wav\n/kaggle/input/ai-paradox/test/00149.wav\n/kaggle/input/ai-paradox/test/00137.wav\n/kaggle/input/ai-paradox/test/00103.wav\n/kaggle/input/ai-paradox/test/00036.wav\n/kaggle/input/ai-paradox/test/00013.wav\n/kaggle/input/ai-paradox/test/00150.wav\n/kaggle/input/ai-paradox/test/00124.wav\n/kaggle/input/ai-paradox/test/00018.wav\n/kaggle/input/ai-paradox/test/00062.wav\n/kaggle/input/ai-paradox/test/00092.wav\n/kaggle/input/ai-paradox/test/00148.wav\n/kaggle/input/ai-paradox/test/00039.wav\n/kaggle/input/ai-paradox/test/00012.wav\n/kaggle/input/ai-paradox/test/00145.wav\n/kaggle/input/ai-paradox/test/00154.wav\n/kaggle/input/ai-paradox/test/00079.wav\n/kaggle/input/ai-paradox/test/00073.wav\n/kaggle/input/ai-paradox/test/00041.wav\n/kaggle/input/ai-paradox/test/00074.wav\n/kaggle/input/ai-paradox/test/00035.wav\n/kaggle/input/ai-paradox/test/00051.wav\n/kaggle/input/ai-paradox/test/00071.wav\n/kaggle/input/ai-paradox/test/00123.wav\n/kaggle/input/ai-paradox/test/00128.wav\n/kaggle/input/ai-paradox/test/00087.wav\n/kaggle/input/ai-paradox/test/00136.wav\n/kaggle/input/ai-paradox/test/00122.wav\n/kaggle/input/ai-paradox/test/00019.wav\n/kaggle/input/ai-paradox/test/00138.wav\n/kaggle/input/ai-paradox/test/00139.wav\n/kaggle/input/ai-paradox/test/00091.wav\n/kaggle/input/ai-paradox/test/00093.wav\n/kaggle/input/ai-paradox/test/00118.wav\n/kaggle/input/ai-paradox/test/00108.wav\n/kaggle/input/ai-paradox/test/00110.wav\n/kaggle/input/ai-paradox/test/00102.wav\n/kaggle/input/ai-paradox/test/00027.wav\n/kaggle/input/ai-paradox/test/00044.wav\n/kaggle/input/ai-paradox/test/00151.wav\n/kaggle/input/ai-paradox/test/00008.wav\n/kaggle/input/ai-paradox/test/00142.wav\n/kaggle/input/ai-paradox/test/00129.wav\n/kaggle/input/ai-paradox/test/00038.wav\n/kaggle/input/ai-paradox/test/00007.wav\n/kaggle/input/ai-paradox/test/00040.wav\n/kaggle/input/ai-paradox/test/00132.wav\n/kaggle/input/ai-paradox/test/00084.wav\n/kaggle/input/ai-paradox/test/00153.wav\n/kaggle/input/ai-paradox/test/00028.wav\n/kaggle/input/ai-paradox/test/00057.wav\n/kaggle/input/ai-paradox/test/00067.wav\n/kaggle/input/ai-paradox/test/00034.wav\n/kaggle/input/ai-paradox/test/00049.wav\n/kaggle/input/ai-paradox/test/00121.wav\n/kaggle/input/ai-paradox/test/00126.wav\n/kaggle/input/ai-paradox/test/00106.wav\n/kaggle/input/ai-paradox/test/00042.wav\n/kaggle/input/ai-paradox/test/00104.wav\n/kaggle/input/ai-paradox/test/00100.wav\n/kaggle/input/ai-paradox/test/00141.wav\n/kaggle/input/ai-paradox/test/00098.wav\n/kaggle/input/ai-paradox/test/00105.wav\n/kaggle/input/ai-paradox/test/00114.wav\n/kaggle/input/ai-paradox/test/00072.wav\n/kaggle/input/ai-paradox/test/00026.wav\n/kaggle/input/ai-paradox/test/00046.wav\n/kaggle/input/ai-paradox/test/00002.wav\n/kaggle/input/ai-paradox/test/00082.wav\n/kaggle/input/ai-paradox/test/00054.wav\n/kaggle/input/ai-paradox/test/00059.wav\n/kaggle/input/ai-paradox/test/00085.wav\n/kaggle/input/ai-paradox/test/00004.wav\n/kaggle/input/ai-paradox/test/00050.wav\n/kaggle/input/ai-paradox/test/00152.wav\n/kaggle/input/ai-paradox/test/00077.wav\n/kaggle/input/ai-paradox/test/00083.wav\n/kaggle/input/ai-paradox/test/00063.wav\n/kaggle/input/ai-paradox/test/00056.wav\n/kaggle/input/ai-paradox/test/00156.wav\n/kaggle/input/ai-paradox/test/00109.wav\n/kaggle/input/ai-paradox/test/00125.wav\n/kaggle/input/ai-paradox/test/00016.wav\n/kaggle/input/ai-paradox/test/00065.wav\n/kaggle/input/ai-paradox/test/00053.wav\n/kaggle/input/ai-paradox/test/00010.wav\n/kaggle/input/ai-paradox/test/00119.wav\n/kaggle/input/ai-paradox/test/00030.wav\n/kaggle/input/ai-paradox/test/00147.wav\n/kaggle/input/ai-paradox/test/00006.wav\n/kaggle/input/ai-paradox/test/00033.wav\n/kaggle/input/ai-paradox/test/00080.wav\n/kaggle/input/ai-paradox/test/00111.wav\n/kaggle/input/ai-paradox/test/00081.wav\n/kaggle/input/ai-paradox/test/00066.wav\n/kaggle/input/ai-paradox/test/00096.wav\n/kaggle/input/ai-paradox/test/00014.wav\n/kaggle/input/ai-paradox/test/00101.wav\n/kaggle/input/ai-paradox/test/00115.wav\n/kaggle/input/ai-paradox/test/00086.wav\n/kaggle/input/ai-paradox/test/00070.wav\n/kaggle/input/ai-paradox/test/00003.wav\n/kaggle/input/ai-paradox/test/00047.wav\n/kaggle/input/ai-paradox/test/00037.wav\n/kaggle/input/ai-paradox/test/00011.wav\n/kaggle/input/ai-paradox/test/00075.wav\n/kaggle/input/ai-paradox/test/00022.wav\n/kaggle/input/ai-paradox/test/00078.wav\n/kaggle/input/ai-paradox/test/00135.wav\n/kaggle/input/ai-paradox/test/00130.wav\n/kaggle/input/ai-paradox/test/00155.wav\n/kaggle/input/ai-paradox/test/00088.wav\n/kaggle/input/ai-paradox/test/00089.wav\n/kaggle/input/ai-paradox/test/00117.wav\n/kaggle/input/ai-paradox/test/00023.wav\n/kaggle/input/ai-paradox/test/00017.wav\n/kaggle/input/ai-paradox/test/00127.wav\n/kaggle/input/ai-paradox/test/00021.wav\n/kaggle/input/ai-paradox/test/00031.wav\n/kaggle/input/ai-paradox/test/00069.wav\n/kaggle/input/ai-paradox/test/00076.wav\n/kaggle/input/ai-paradox/test/00112.wav\n/kaggle/input/ai-paradox/test/00146.wav\n/kaggle/input/ai-paradox/test/00143.wav\n/kaggle/input/ai-paradox/test/00048.wav\n/kaggle/input/ai-paradox/test/00060.wav\n/kaggle/input/ai-paradox/test/00140.wav\n/kaggle/input/ai-paradox/test/00001.wav\n/kaggle/input/ai-paradox/test/00095.wav\n/kaggle/input/ai-paradox/test/00134.wav\n/kaggle/input/ai-paradox/test/00133.wav\n/kaggle/input/ai-paradox/test/00009.wav\n/kaggle/input/ai-paradox/test/00032.wav\n/kaggle/input/ai-paradox/test/00005.wav\n/kaggle/input/ai-paradox/test/00029.wav\n/kaggle/input/ai-paradox/test/00064.wav\n/kaggle/input/ai-paradox/test/00068.wav\n/kaggle/input/ai-paradox/train/normal/000156.wav\n/kaggle/input/ai-paradox/train/normal/000060.wav\n/kaggle/input/ai-paradox/train/normal/000375.wav\n/kaggle/input/ai-paradox/train/normal/000012.wav\n/kaggle/input/ai-paradox/train/normal/000162.wav\n/kaggle/input/ai-paradox/train/normal/000331.wav\n/kaggle/input/ai-paradox/train/normal/000021.wav\n/kaggle/input/ai-paradox/train/normal/000352.wav\n/kaggle/input/ai-paradox/train/normal/000394.wav\n/kaggle/input/ai-paradox/train/normal/000424.wav\n/kaggle/input/ai-paradox/train/normal/000249.wav\n/kaggle/input/ai-paradox/train/normal/000344.wav\n/kaggle/input/ai-paradox/train/normal/000398.wav\n/kaggle/input/ai-paradox/train/normal/000369.wav\n/kaggle/input/ai-paradox/train/normal/000326.wav\n/kaggle/input/ai-paradox/train/normal/000164.wav\n/kaggle/input/ai-paradox/train/normal/000422.wav\n/kaggle/input/ai-paradox/train/normal/000165.wav\n/kaggle/input/ai-paradox/train/normal/000061.wav\n/kaggle/input/ai-paradox/train/normal/000031.wav\n/kaggle/input/ai-paradox/train/normal/000168.wav\n/kaggle/input/ai-paradox/train/normal/000411.wav\n/kaggle/input/ai-paradox/train/normal/000128.wav\n/kaggle/input/ai-paradox/train/normal/000254.wav\n/kaggle/input/ai-paradox/train/normal/000088.wav\n/kaggle/input/ai-paradox/train/normal/000282.wav\n/kaggle/input/ai-paradox/train/normal/000099.wav\n/kaggle/input/ai-paradox/train/normal/000033.wav\n/kaggle/input/ai-paradox/train/normal/000083.wav\n/kaggle/input/ai-paradox/train/normal/000391.wav\n/kaggle/input/ai-paradox/train/normal/000360.wav\n/kaggle/input/ai-paradox/train/normal/000378.wav\n/kaggle/input/ai-paradox/train/normal/000442.wav\n/kaggle/input/ai-paradox/train/normal/000434.wav\n/kaggle/input/ai-paradox/train/normal/000233.wav\n/kaggle/input/ai-paradox/train/normal/000234.wav\n/kaggle/input/ai-paradox/train/normal/000023.wav\n/kaggle/input/ai-paradox/train/normal/000295.wav\n/kaggle/input/ai-paradox/train/normal/000356.wav\n/kaggle/input/ai-paradox/train/normal/000082.wav\n/kaggle/input/ai-paradox/train/normal/000419.wav\n/kaggle/input/ai-paradox/train/normal/000409.wav\n/kaggle/input/ai-paradox/train/normal/000041.wav\n/kaggle/input/ai-paradox/train/normal/000130.wav\n/kaggle/input/ai-paradox/train/normal/000224.wav\n/kaggle/input/ai-paradox/train/normal/000388.wav\n/kaggle/input/ai-paradox/train/normal/000115.wav\n/kaggle/input/ai-paradox/train/normal/000380.wav\n/kaggle/input/ai-paradox/train/normal/000205.wav\n/kaggle/input/ai-paradox/train/normal/000106.wav\n/kaggle/input/ai-paradox/train/normal/000384.wav\n/kaggle/input/ai-paradox/train/normal/000212.wav\n/kaggle/input/ai-paradox/train/normal/000261.wav\n/kaggle/input/ai-paradox/train/normal/000266.wav\n/kaggle/input/ai-paradox/train/normal/000401.wav\n/kaggle/input/ai-paradox/train/normal/000069.wav\n/kaggle/input/ai-paradox/train/normal/000143.wav\n/kaggle/input/ai-paradox/train/normal/000258.wav\n/kaggle/input/ai-paradox/train/normal/000197.wav\n/kaggle/input/ai-paradox/train/normal/000229.wav\n/kaggle/input/ai-paradox/train/normal/000283.wav\n/kaggle/input/ai-paradox/train/normal/000382.wav\n/kaggle/input/ai-paradox/train/normal/000355.wav\n/kaggle/input/ai-paradox/train/normal/000315.wav\n/kaggle/input/ai-paradox/train/normal/000121.wav\n/kaggle/input/ai-paradox/train/normal/000146.wav\n/kaggle/input/ai-paradox/train/normal/000287.wav\n/kaggle/input/ai-paradox/train/normal/000348.wav\n/kaggle/input/ai-paradox/train/normal/000303.wav\n/kaggle/input/ai-paradox/train/normal/000273.wav\n/kaggle/input/ai-paradox/train/normal/000239.wav\n/kaggle/input/ai-paradox/train/normal/000211.wav\n/kaggle/input/ai-paradox/train/normal/000009.wav\n/kaggle/input/ai-paradox/train/normal/000200.wav\n/kaggle/input/ai-paradox/train/normal/000024.wav\n/kaggle/input/ai-paradox/train/normal/000443.wav\n/kaggle/input/ai-paradox/train/normal/000036.wav\n/kaggle/input/ai-paradox/train/normal/000094.wav\n/kaggle/input/ai-paradox/train/normal/000071.wav\n/kaggle/input/ai-paradox/train/normal/000393.wav\n/kaggle/input/ai-paradox/train/normal/000413.wav\n/kaggle/input/ai-paradox/train/normal/000372.wav\n/kaggle/input/ai-paradox/train/normal/000250.wav\n/kaggle/input/ai-paradox/train/normal/000187.wav\n/kaggle/input/ai-paradox/train/normal/000134.wav\n/kaggle/input/ai-paradox/train/normal/000245.wav\n/kaggle/input/ai-paradox/train/normal/000064.wav\n/kaggle/input/ai-paradox/train/normal/000186.wav\n/kaggle/input/ai-paradox/train/normal/000138.wav\n/kaggle/input/ai-paradox/train/normal/000438.wav\n/kaggle/input/ai-paradox/train/normal/000171.wav\n/kaggle/input/ai-paradox/train/normal/000313.wav\n/kaggle/input/ai-paradox/train/normal/000336.wav\n/kaggle/input/ai-paradox/train/normal/000301.wav\n/kaggle/input/ai-paradox/train/normal/000056.wav\n/kaggle/input/ai-paradox/train/normal/000017.wav\n/kaggle/input/ai-paradox/train/normal/000350.wav\n/kaggle/input/ai-paradox/train/normal/000048.wav\n/kaggle/input/ai-paradox/train/normal/000342.wav\n/kaggle/input/ai-paradox/train/normal/000334.wav\n/kaggle/input/ai-paradox/train/normal/000006.wav\n/kaggle/input/ai-paradox/train/normal/000345.wav\n/kaggle/input/ai-paradox/train/normal/000341.wav\n/kaggle/input/ai-paradox/train/normal/000404.wav\n/kaggle/input/ai-paradox/train/normal/000427.wav\n/kaggle/input/ai-paradox/train/normal/000125.wav\n/kaggle/input/ai-paradox/train/normal/000191.wav\n/kaggle/input/ai-paradox/train/normal/000046.wav\n/kaggle/input/ai-paradox/train/normal/000175.wav\n/kaggle/input/ai-paradox/train/normal/000067.wav\n/kaggle/input/ai-paradox/train/normal/000431.wav\n/kaggle/input/ai-paradox/train/normal/000147.wav\n/kaggle/input/ai-paradox/train/normal/000084.wav\n/kaggle/input/ai-paradox/train/normal/000080.wav\n/kaggle/input/ai-paradox/train/normal/000042.wav\n/kaggle/input/ai-paradox/train/normal/000180.wav\n/kaggle/input/ai-paradox/train/normal/000323.wav\n/kaggle/input/ai-paradox/train/normal/000441.wav\n/kaggle/input/ai-paradox/train/normal/000351.wav\n/kaggle/input/ai-paradox/train/normal/000035.wav\n/kaggle/input/ai-paradox/train/normal/000216.wav\n/kaggle/input/ai-paradox/train/normal/000445.wav\n/kaggle/input/ai-paradox/train/normal/000050.wav\n/kaggle/input/ai-paradox/train/normal/000198.wav\n/kaggle/input/ai-paradox/train/normal/000095.wav\n/kaggle/input/ai-paradox/train/normal/000279.wav\n/kaggle/input/ai-paradox/train/normal/000086.wav\n/kaggle/input/ai-paradox/train/normal/000179.wav\n/kaggle/input/ai-paradox/train/normal/000418.wav\n/kaggle/input/ai-paradox/train/normal/000202.wav\n/kaggle/input/ai-paradox/train/normal/000057.wav\n/kaggle/input/ai-paradox/train/normal/000103.wav\n/kaggle/input/ai-paradox/train/normal/000332.wav\n/kaggle/input/ai-paradox/train/normal/000257.wav\n/kaggle/input/ai-paradox/train/normal/000338.wav\n/kaggle/input/ai-paradox/train/normal/000269.wav\n/kaggle/input/ai-paradox/train/normal/000026.wav\n/kaggle/input/ai-paradox/train/normal/000453.wav\n/kaggle/input/ai-paradox/train/normal/000265.wav\n/kaggle/input/ai-paradox/train/normal/000451.wav\n/kaggle/input/ai-paradox/train/normal/000400.wav\n/kaggle/input/ai-paradox/train/normal/000189.wav\n/kaggle/input/ai-paradox/train/normal/000065.wav\n/kaggle/input/ai-paradox/train/normal/000457.wav\n/kaggle/input/ai-paradox/train/normal/000178.wav\n/kaggle/input/ai-paradox/train/normal/000116.wav\n/kaggle/input/ai-paradox/train/normal/000241.wav\n/kaggle/input/ai-paradox/train/normal/000158.wav\n/kaggle/input/ai-paradox/train/normal/000037.wav\n/kaggle/input/ai-paradox/train/normal/000366.wav\n/kaggle/input/ai-paradox/train/normal/000109.wav\n/kaggle/input/ai-paradox/train/normal/000014.wav\n/kaggle/input/ai-paradox/train/normal/000358.wav\n/kaggle/input/ai-paradox/train/normal/000004.wav\n/kaggle/input/ai-paradox/train/normal/000381.wav\n/kaggle/input/ai-paradox/train/normal/000213.wav\n/kaggle/input/ai-paradox/train/normal/000276.wav\n/kaggle/input/ai-paradox/train/normal/000148.wav\n/kaggle/input/ai-paradox/train/normal/000277.wav\n/kaggle/input/ai-paradox/train/normal/000097.wav\n/kaggle/input/ai-paradox/train/normal/000251.wav\n/kaggle/input/ai-paradox/train/normal/000201.wav\n/kaggle/input/ai-paradox/train/normal/000081.wav\n/kaggle/input/ai-paradox/train/normal/000204.wav\n/kaggle/input/ai-paradox/train/normal/000144.wav\n/kaggle/input/ai-paradox/train/normal/000163.wav\n/kaggle/input/ai-paradox/train/normal/000075.wav\n/kaggle/input/ai-paradox/train/normal/000214.wav\n/kaggle/input/ai-paradox/train/normal/000290.wav\n/kaggle/input/ai-paradox/train/normal/000240.wav\n/kaggle/input/ai-paradox/train/normal/000397.wav\n/kaggle/input/ai-paradox/train/normal/000155.wav\n/kaggle/input/ai-paradox/train/normal/000364.wav\n/kaggle/input/ai-paradox/train/normal/000256.wav\n/kaggle/input/ai-paradox/train/normal/000039.wav\n/kaggle/input/ai-paradox/train/normal/000140.wav\n/kaggle/input/ai-paradox/train/normal/000096.wav\n/kaggle/input/ai-paradox/train/normal/000448.wav\n/kaggle/input/ai-paradox/train/normal/000387.wav\n/kaggle/input/ai-paradox/train/normal/000181.wav\n/kaggle/input/ai-paradox/train/normal/000127.wav\n/kaggle/input/ai-paradox/train/normal/000281.wav\n/kaggle/input/ai-paradox/train/normal/000440.wav\n/kaggle/input/ai-paradox/train/normal/000100.wav\n/kaggle/input/ai-paradox/train/normal/000361.wav\n/kaggle/input/ai-paradox/train/normal/000377.wav\n/kaggle/input/ai-paradox/train/normal/000340.wav\n/kaggle/input/ai-paradox/train/normal/000072.wav\n/kaggle/input/ai-paradox/train/normal/000317.wav\n/kaggle/input/ai-paradox/train/normal/000003.wav\n/kaggle/input/ai-paradox/train/normal/000335.wav\n/kaggle/input/ai-paradox/train/normal/000383.wav\n/kaggle/input/ai-paradox/train/normal/000353.wav\n/kaggle/input/ai-paradox/train/normal/000399.wav\n/kaggle/input/ai-paradox/train/normal/000415.wav\n/kaggle/input/ai-paradox/train/normal/000059.wav\n/kaggle/input/ai-paradox/train/normal/000319.wav\n/kaggle/input/ai-paradox/train/normal/000227.wav\n/kaggle/input/ai-paradox/train/normal/000169.wav\n/kaggle/input/ai-paradox/train/normal/000170.wav\n/kaggle/input/ai-paradox/train/normal/000362.wav\n/kaggle/input/ai-paradox/train/normal/000217.wav\n/kaggle/input/ai-paradox/train/normal/000238.wav\n/kaggle/input/ai-paradox/train/normal/000416.wav\n/kaggle/input/ai-paradox/train/normal/000011.wav\n/kaggle/input/ai-paradox/train/normal/000025.wav\n/kaggle/input/ai-paradox/train/normal/000117.wav\n/kaggle/input/ai-paradox/train/normal/000357.wav\n/kaggle/input/ai-paradox/train/normal/000288.wav\n/kaggle/input/ai-paradox/train/normal/000395.wav\n/kaggle/input/ai-paradox/train/normal/000294.wav\n/kaggle/input/ai-paradox/train/normal/000252.wav\n/kaggle/input/ai-paradox/train/normal/000098.wav\n/kaggle/input/ai-paradox/train/normal/000221.wav\n/kaggle/input/ai-paradox/train/normal/000278.wav\n/kaggle/input/ai-paradox/train/normal/000208.wav\n/kaggle/input/ai-paradox/train/normal/000160.wav\n/kaggle/input/ai-paradox/train/normal/000126.wav\n/kaggle/input/ai-paradox/train/normal/000248.wav\n/kaggle/input/ai-paradox/train/normal/000118.wav\n/kaggle/input/ai-paradox/train/normal/000371.wav\n/kaggle/input/ai-paradox/train/normal/000022.wav\n/kaggle/input/ai-paradox/train/normal/000304.wav\n/kaggle/input/ai-paradox/train/normal/000455.wav\n/kaggle/input/ai-paradox/train/normal/000078.wav\n/kaggle/input/ai-paradox/train/normal/000154.wav\n/kaggle/input/ai-paradox/train/normal/000223.wav\n/kaggle/input/ai-paradox/train/normal/000058.wav\n/kaggle/input/ai-paradox/train/normal/000218.wav\n/kaggle/input/ai-paradox/train/normal/000136.wav\n/kaggle/input/ai-paradox/train/normal/000426.wav\n/kaggle/input/ai-paradox/train/normal/000051.wav\n/kaggle/input/ai-paradox/train/normal/000314.wav\n/kaggle/input/ai-paradox/train/normal/000222.wav\n/kaggle/input/ai-paradox/train/normal/000264.wav\n/kaggle/input/ai-paradox/train/normal/000349.wav\n/kaggle/input/ai-paradox/train/normal/000420.wav\n/kaggle/input/ai-paradox/train/normal/000151.wav\n/kaggle/input/ai-paradox/train/normal/000032.wav\n/kaggle/input/ai-paradox/train/normal/000346.wav\n/kaggle/input/ai-paradox/train/normal/000428.wav\n/kaggle/input/ai-paradox/train/normal/000063.wav\n/kaggle/input/ai-paradox/train/normal/000076.wav\n/kaggle/input/ai-paradox/train/normal/000029.wav\n/kaggle/input/ai-paradox/train/normal/000408.wav\n/kaggle/input/ai-paradox/train/normal/000070.wav\n/kaggle/input/ai-paradox/train/normal/000253.wav\n/kaggle/input/ai-paradox/train/normal/000113.wav\n/kaggle/input/ai-paradox/train/normal/000182.wav\n/kaggle/input/ai-paradox/train/normal/000312.wav\n/kaggle/input/ai-paradox/train/normal/000272.wav\n/kaggle/input/ai-paradox/train/normal/000087.wav\n/kaggle/input/ai-paradox/train/normal/000347.wav\n/kaggle/input/ai-paradox/train/normal/000040.wav\n/kaggle/input/ai-paradox/train/normal/000367.wav\n/kaggle/input/ai-paradox/train/normal/000339.wav\n/kaggle/input/ai-paradox/train/normal/000015.wav\n/kaggle/input/ai-paradox/train/normal/000105.wav\n/kaggle/input/ai-paradox/train/normal/000027.wav\n/kaggle/input/ai-paradox/train/normal/000005.wav\n/kaggle/input/ai-paradox/train/normal/000183.wav\n/kaggle/input/ai-paradox/train/normal/000330.wav\n/kaggle/input/ai-paradox/train/normal/000296.wav\n/kaggle/input/ai-paradox/train/normal/000111.wav\n/kaggle/input/ai-paradox/train/normal/000152.wav\n/kaggle/input/ai-paradox/train/normal/000260.wav\n/kaggle/input/ai-paradox/train/normal/000421.wav\n/kaggle/input/ai-paradox/train/normal/000135.wav\n/kaggle/input/ai-paradox/train/normal/000207.wav\n/kaggle/input/ai-paradox/train/normal/000298.wav\n/kaggle/input/ai-paradox/train/normal/000318.wav\n/kaggle/input/ai-paradox/train/normal/000077.wav\n/kaggle/input/ai-paradox/train/normal/000363.wav\n/kaggle/input/ai-paradox/train/normal/000132.wav\n/kaggle/input/ai-paradox/train/normal/000194.wav\n/kaggle/input/ai-paradox/train/normal/000226.wav\n/kaggle/input/ai-paradox/train/normal/000444.wav\n/kaggle/input/ai-paradox/train/normal/000044.wav\n/kaggle/input/ai-paradox/train/normal/000102.wav\n/kaggle/input/ai-paradox/train/normal/000262.wav\n/kaggle/input/ai-paradox/train/normal/000302.wav\n/kaggle/input/ai-paradox/train/normal/000379.wav\n/kaggle/input/ai-paradox/train/normal/000137.wav\n/kaggle/input/ai-paradox/train/normal/000275.wav\n/kaggle/input/ai-paradox/train/normal/000359.wav\n/kaggle/input/ai-paradox/train/normal/000209.wav\n/kaggle/input/ai-paradox/train/normal/000322.wav\n/kaggle/input/ai-paradox/train/normal/000220.wav\n/kaggle/input/ai-paradox/train/normal/000066.wav\n/kaggle/input/ai-paradox/train/normal/000247.wav\n/kaggle/input/ai-paradox/train/normal/000450.wav\n/kaggle/input/ai-paradox/train/normal/000110.wav\n/kaggle/input/ai-paradox/train/normal/000232.wav\n/kaggle/input/ai-paradox/train/normal/000365.wav\n/kaggle/input/ai-paradox/train/normal/000030.wav\n/kaggle/input/ai-paradox/train/normal/000406.wav\n/kaggle/input/ai-paradox/train/normal/000385.wav\n/kaggle/input/ai-paradox/train/normal/000433.wav\n/kaggle/input/ai-paradox/train/normal/000016.wav\n/kaggle/input/ai-paradox/train/normal/000053.wav\n/kaggle/input/ai-paradox/train/normal/000079.wav\n/kaggle/input/ai-paradox/train/normal/000291.wav\n/kaggle/input/ai-paradox/train/normal/000085.wav\n/kaggle/input/ai-paradox/train/normal/000196.wav\n/kaggle/input/ai-paradox/train/normal/000112.wav\n/kaggle/input/ai-paradox/train/normal/000429.wav\n/kaggle/input/ai-paradox/train/normal/000038.wav\n/kaggle/input/ai-paradox/train/normal/000090.wav\n/kaggle/input/ai-paradox/train/normal/000373.wav\n/kaggle/input/ai-paradox/train/normal/000307.wav\n/kaggle/input/ai-paradox/train/normal/000243.wav\n/kaggle/input/ai-paradox/train/normal/000074.wav\n/kaggle/input/ai-paradox/train/normal/000284.wav\n/kaggle/input/ai-paradox/train/normal/000430.wav\n/kaggle/input/ai-paradox/train/normal/000324.wav\n/kaggle/input/ai-paradox/train/normal/000321.wav\n/kaggle/input/ai-paradox/train/normal/000452.wav\n/kaggle/input/ai-paradox/train/normal/000337.wav\n/kaggle/input/ai-paradox/train/normal/000270.wav\n/kaggle/input/ai-paradox/train/normal/000045.wav\n/kaggle/input/ai-paradox/train/normal/000120.wav\n/kaggle/input/ai-paradox/train/normal/000407.wav\n/kaggle/input/ai-paradox/train/normal/000091.wav\n/kaggle/input/ai-paradox/train/normal/000215.wav\n/kaggle/input/ai-paradox/train/normal/000166.wav\n/kaggle/input/ai-paradox/train/normal/000289.wav\n/kaggle/input/ai-paradox/train/normal/000052.wav\n/kaggle/input/ai-paradox/train/normal/000119.wav\n/kaggle/input/ai-paradox/train/normal/000405.wav\n/kaggle/input/ai-paradox/train/normal/000306.wav\n/kaggle/input/ai-paradox/train/normal/000327.wav\n/kaggle/input/ai-paradox/train/normal/000374.wav\n/kaggle/input/ai-paradox/train/normal/000231.wav\n/kaggle/input/ai-paradox/train/normal/000437.wav\n/kaggle/input/ai-paradox/train/normal/000325.wav\n/kaggle/input/ai-paradox/train/normal/000172.wav\n/kaggle/input/ai-paradox/train/normal/000124.wav\n/kaggle/input/ai-paradox/train/normal/000244.wav\n/kaggle/input/ai-paradox/train/normal/000267.wav\n/kaggle/input/ai-paradox/train/normal/000376.wav\n/kaggle/input/ai-paradox/train/normal/000010.wav\n/kaggle/input/ai-paradox/train/normal/000104.wav\n/kaggle/input/ai-paradox/train/normal/000403.wav\n/kaggle/input/ai-paradox/train/normal/000432.wav\n/kaggle/input/ai-paradox/train/normal/000320.wav\n/kaggle/input/ai-paradox/train/normal/000271.wav\n/kaggle/input/ai-paradox/train/normal/000114.wav\n/kaggle/input/ai-paradox/train/normal/000228.wav\n/kaggle/input/ai-paradox/train/normal/000177.wav\n/kaggle/input/ai-paradox/train/normal/000410.wav\n/kaggle/input/ai-paradox/train/normal/000049.wav\n/kaggle/input/ai-paradox/train/normal/000192.wav\n/kaggle/input/ai-paradox/train/normal/000007.wav\n/kaggle/input/ai-paradox/train/normal/000274.wav\n/kaggle/input/ai-paradox/train/normal/000054.wav\n/kaggle/input/ai-paradox/train/normal/000199.wav\n/kaggle/input/ai-paradox/train/normal/000142.wav\n/kaggle/input/ai-paradox/train/normal/000203.wav\n/kaggle/input/ai-paradox/train/normal/000286.wav\n/kaggle/input/ai-paradox/train/normal/000206.wav\n/kaggle/input/ai-paradox/train/normal/000300.wav\n/kaggle/input/ai-paradox/train/normal/000392.wav\n/kaggle/input/ai-paradox/train/normal/000246.wav\n/kaggle/input/ai-paradox/train/normal/000412.wav\n/kaggle/input/ai-paradox/train/normal/000280.wav\n/kaggle/input/ai-paradox/train/normal/000292.wav\n/kaggle/input/ai-paradox/train/normal/000089.wav\n/kaggle/input/ai-paradox/train/normal/000131.wav\n/kaggle/input/ai-paradox/train/normal/000447.wav\n/kaggle/input/ai-paradox/train/normal/000093.wav\n/kaggle/input/ai-paradox/train/normal/000435.wav\n/kaggle/input/ai-paradox/train/normal/000333.wav\n/kaggle/input/ai-paradox/train/normal/000001.wav\n/kaggle/input/ai-paradox/train/normal/000092.wav\n/kaggle/input/ai-paradox/train/normal/000354.wav\n/kaggle/input/ai-paradox/train/normal/000308.wav\n/kaggle/input/ai-paradox/train/normal/000047.wav\n/kaggle/input/ai-paradox/train/normal/000236.wav\n/kaggle/input/ai-paradox/train/normal/000020.wav\n/kaggle/input/ai-paradox/train/normal/000263.wav\n/kaggle/input/ai-paradox/train/normal/000449.wav\n/kaggle/input/ai-paradox/train/normal/000129.wav\n/kaggle/input/ai-paradox/train/normal/000190.wav\n/kaggle/input/ai-paradox/train/normal/000185.wav\n/kaggle/input/ai-paradox/train/normal/000176.wav\n/kaggle/input/ai-paradox/train/normal/000305.wav\n/kaggle/input/ai-paradox/train/normal/000034.wav\n/kaggle/input/ai-paradox/train/normal/000237.wav\n/kaggle/input/ai-paradox/train/normal/000343.wav\n/kaggle/input/ai-paradox/train/normal/000368.wav\n/kaggle/input/ai-paradox/train/normal/000188.wav\n/kaggle/input/ai-paradox/train/normal/000310.wav\n/kaggle/input/ai-paradox/train/normal/000299.wav\n/kaggle/input/ai-paradox/train/normal/000446.wav\n/kaggle/input/ai-paradox/train/normal/000195.wav\n/kaggle/input/ai-paradox/train/normal/000255.wav\n/kaggle/input/ai-paradox/train/normal/000141.wav\n/kaggle/input/ai-paradox/train/normal/000219.wav\n/kaggle/input/ai-paradox/train/normal/000019.wav\n/kaggle/input/ai-paradox/train/normal/000055.wav\n/kaggle/input/ai-paradox/train/normal/000386.wav\n/kaggle/input/ai-paradox/train/normal/000139.wav\n/kaggle/input/ai-paradox/train/normal/000150.wav\n/kaggle/input/ai-paradox/train/normal/000018.wav\n/kaggle/input/ai-paradox/train/normal/000013.wav\n/kaggle/input/ai-paradox/train/normal/000002.wav\n/kaggle/input/ai-paradox/train/normal/000285.wav\n/kaggle/input/ai-paradox/train/normal/000425.wav\n/kaggle/input/ai-paradox/train/normal/000396.wav\n/kaggle/input/ai-paradox/train/normal/000123.wav\n/kaggle/input/ai-paradox/train/normal/000268.wav\n/kaggle/input/ai-paradox/train/normal/000454.wav\n/kaggle/input/ai-paradox/train/normal/000297.wav\n/kaggle/input/ai-paradox/train/normal/000309.wav\n/kaggle/input/ai-paradox/train/normal/000293.wav\n/kaggle/input/ai-paradox/train/normal/000414.wav\n/kaggle/input/ai-paradox/train/normal/000193.wav\n/kaggle/input/ai-paradox/train/normal/000423.wav\n/kaggle/input/ai-paradox/train/normal/000402.wav\n/kaggle/input/ai-paradox/train/normal/000184.wav\n/kaggle/input/ai-paradox/train/normal/000167.wav\n/kaggle/input/ai-paradox/train/normal/000390.wav\n/kaggle/input/ai-paradox/train/normal/000149.wav\n/kaggle/input/ai-paradox/train/normal/000101.wav\n/kaggle/input/ai-paradox/train/normal/000235.wav\n/kaggle/input/ai-paradox/train/normal/000028.wav\n/kaggle/input/ai-paradox/train/normal/000159.wav\n/kaggle/input/ai-paradox/train/normal/000316.wav\n/kaggle/input/ai-paradox/train/normal/000370.wav\n/kaggle/input/ai-paradox/train/normal/000145.wav\n/kaggle/input/ai-paradox/train/normal/000225.wav\n/kaggle/input/ai-paradox/train/normal/000259.wav\n/kaggle/input/ai-paradox/train/normal/000174.wav\n/kaggle/input/ai-paradox/train/normal/000157.wav\n/kaggle/input/ai-paradox/train/normal/000043.wav\n/kaggle/input/ai-paradox/train/normal/000062.wav\n/kaggle/input/ai-paradox/train/normal/000328.wav\n/kaggle/input/ai-paradox/train/normal/000068.wav\n/kaggle/input/ai-paradox/train/normal/000133.wav\n/kaggle/input/ai-paradox/train/normal/000107.wav\n/kaggle/input/ai-paradox/train/normal/000329.wav\n/kaggle/input/ai-paradox/train/normal/000073.wav\n/kaggle/input/ai-paradox/train/normal/000153.wav\n/kaggle/input/ai-paradox/train/normal/000008.wav\n/kaggle/input/ai-paradox/train/normal/000456.wav\n/kaggle/input/ai-paradox/train/normal/000173.wav\n/kaggle/input/ai-paradox/train/normal/000311.wav\n/kaggle/input/ai-paradox/train/normal/000230.wav\n/kaggle/input/ai-paradox/train/normal/000417.wav\n/kaggle/input/ai-paradox/train/normal/000439.wav\n/kaggle/input/ai-paradox/train/normal/000389.wav\n/kaggle/input/ai-paradox/train/normal/000242.wav\n/kaggle/input/ai-paradox/train/normal/000161.wav\n/kaggle/input/ai-paradox/train/normal/000436.wav\n/kaggle/input/ai-paradox/train/normal/000108.wav\n/kaggle/input/ai-paradox/train/normal/000210.wav\n/kaggle/input/ai-paradox/train/normal/000122.wav\n/kaggle/input/ai-paradox/train/abnormal/000156.wav\n/kaggle/input/ai-paradox/train/abnormal/000060.wav\n/kaggle/input/ai-paradox/train/abnormal/000012.wav\n/kaggle/input/ai-paradox/train/abnormal/000162.wav\n/kaggle/input/ai-paradox/train/abnormal/000021.wav\n/kaggle/input/ai-paradox/train/abnormal/000164.wav\n/kaggle/input/ai-paradox/train/abnormal/000165.wav\n/kaggle/input/ai-paradox/train/abnormal/000061.wav\n/kaggle/input/ai-paradox/train/abnormal/000031.wav\n/kaggle/input/ai-paradox/train/abnormal/000128.wav\n/kaggle/input/ai-paradox/train/abnormal/000088.wav\n/kaggle/input/ai-paradox/train/abnormal/000099.wav\n/kaggle/input/ai-paradox/train/abnormal/000033.wav\n/kaggle/input/ai-paradox/train/abnormal/000083.wav\n/kaggle/input/ai-paradox/train/abnormal/000023.wav\n/kaggle/input/ai-paradox/train/abnormal/000082.wav\n/kaggle/input/ai-paradox/train/abnormal/000041.wav\n/kaggle/input/ai-paradox/train/abnormal/000130.wav\n/kaggle/input/ai-paradox/train/abnormal/000115.wav\n/kaggle/input/ai-paradox/train/abnormal/000106.wav\n/kaggle/input/ai-paradox/train/abnormal/000069.wav\n/kaggle/input/ai-paradox/train/abnormal/000143.wav\n/kaggle/input/ai-paradox/train/abnormal/000121.wav\n/kaggle/input/ai-paradox/train/abnormal/000146.wav\n/kaggle/input/ai-paradox/train/abnormal/000009.wav\n/kaggle/input/ai-paradox/train/abnormal/000024.wav\n/kaggle/input/ai-paradox/train/abnormal/000036.wav\n/kaggle/input/ai-paradox/train/abnormal/000094.wav\n/kaggle/input/ai-paradox/train/abnormal/000071.wav\n/kaggle/input/ai-paradox/train/abnormal/000134.wav\n/kaggle/input/ai-paradox/train/abnormal/000064.wav\n/kaggle/input/ai-paradox/train/abnormal/000138.wav\n/kaggle/input/ai-paradox/train/abnormal/000056.wav\n/kaggle/input/ai-paradox/train/abnormal/000017.wav\n/kaggle/input/ai-paradox/train/abnormal/000048.wav\n/kaggle/input/ai-paradox/train/abnormal/000006.wav\n/kaggle/input/ai-paradox/train/abnormal/000125.wav\n/kaggle/input/ai-paradox/train/abnormal/000046.wav\n/kaggle/input/ai-paradox/train/abnormal/000067.wav\n/kaggle/input/ai-paradox/train/abnormal/000147.wav\n/kaggle/input/ai-paradox/train/abnormal/000084.wav\n/kaggle/input/ai-paradox/train/abnormal/000080.wav\n/kaggle/input/ai-paradox/train/abnormal/000042.wav\n/kaggle/input/ai-paradox/train/abnormal/000035.wav\n/kaggle/input/ai-paradox/train/abnormal/000050.wav\n/kaggle/input/ai-paradox/train/abnormal/000095.wav\n/kaggle/input/ai-paradox/train/abnormal/000086.wav\n/kaggle/input/ai-paradox/train/abnormal/000057.wav\n/kaggle/input/ai-paradox/train/abnormal/000103.wav\n/kaggle/input/ai-paradox/train/abnormal/000026.wav\n/kaggle/input/ai-paradox/train/abnormal/000065.wav\n/kaggle/input/ai-paradox/train/abnormal/000116.wav\n/kaggle/input/ai-paradox/train/abnormal/000158.wav\n/kaggle/input/ai-paradox/train/abnormal/000037.wav\n/kaggle/input/ai-paradox/train/abnormal/000109.wav\n/kaggle/input/ai-paradox/train/abnormal/000014.wav\n/kaggle/input/ai-paradox/train/abnormal/000004.wav\n/kaggle/input/ai-paradox/train/abnormal/000148.wav\n/kaggle/input/ai-paradox/train/abnormal/000097.wav\n/kaggle/input/ai-paradox/train/abnormal/000081.wav\n/kaggle/input/ai-paradox/train/abnormal/000144.wav\n/kaggle/input/ai-paradox/train/abnormal/000163.wav\n/kaggle/input/ai-paradox/train/abnormal/000075.wav\n/kaggle/input/ai-paradox/train/abnormal/000155.wav\n/kaggle/input/ai-paradox/train/abnormal/000039.wav\n/kaggle/input/ai-paradox/train/abnormal/000140.wav\n/kaggle/input/ai-paradox/train/abnormal/000096.wav\n/kaggle/input/ai-paradox/train/abnormal/000127.wav\n/kaggle/input/ai-paradox/train/abnormal/000100.wav\n/kaggle/input/ai-paradox/train/abnormal/000072.wav\n/kaggle/input/ai-paradox/train/abnormal/000003.wav\n/kaggle/input/ai-paradox/train/abnormal/000059.wav\n/kaggle/input/ai-paradox/train/abnormal/000011.wav\n/kaggle/input/ai-paradox/train/abnormal/000025.wav\n/kaggle/input/ai-paradox/train/abnormal/000117.wav\n/kaggle/input/ai-paradox/train/abnormal/000098.wav\n/kaggle/input/ai-paradox/train/abnormal/000160.wav\n/kaggle/input/ai-paradox/train/abnormal/000126.wav\n/kaggle/input/ai-paradox/train/abnormal/000118.wav\n/kaggle/input/ai-paradox/train/abnormal/000022.wav\n/kaggle/input/ai-paradox/train/abnormal/000078.wav\n/kaggle/input/ai-paradox/train/abnormal/000154.wav\n/kaggle/input/ai-paradox/train/abnormal/000058.wav\n/kaggle/input/ai-paradox/train/abnormal/000136.wav\n/kaggle/input/ai-paradox/train/abnormal/000051.wav\n/kaggle/input/ai-paradox/train/abnormal/000151.wav\n/kaggle/input/ai-paradox/train/abnormal/000032.wav\n/kaggle/input/ai-paradox/train/abnormal/000063.wav\n/kaggle/input/ai-paradox/train/abnormal/000076.wav\n/kaggle/input/ai-paradox/train/abnormal/000029.wav\n/kaggle/input/ai-paradox/train/abnormal/000070.wav\n/kaggle/input/ai-paradox/train/abnormal/000113.wav\n/kaggle/input/ai-paradox/train/abnormal/000087.wav\n/kaggle/input/ai-paradox/train/abnormal/000040.wav\n/kaggle/input/ai-paradox/train/abnormal/000015.wav\n/kaggle/input/ai-paradox/train/abnormal/000105.wav\n/kaggle/input/ai-paradox/train/abnormal/000027.wav\n/kaggle/input/ai-paradox/train/abnormal/000005.wav\n/kaggle/input/ai-paradox/train/abnormal/000111.wav\n/kaggle/input/ai-paradox/train/abnormal/000152.wav\n/kaggle/input/ai-paradox/train/abnormal/000135.wav\n/kaggle/input/ai-paradox/train/abnormal/000077.wav\n/kaggle/input/ai-paradox/train/abnormal/000132.wav\n/kaggle/input/ai-paradox/train/abnormal/000044.wav\n/kaggle/input/ai-paradox/train/abnormal/000102.wav\n/kaggle/input/ai-paradox/train/abnormal/000137.wav\n/kaggle/input/ai-paradox/train/abnormal/000066.wav\n/kaggle/input/ai-paradox/train/abnormal/000110.wav\n/kaggle/input/ai-paradox/train/abnormal/000030.wav\n/kaggle/input/ai-paradox/train/abnormal/000016.wav\n/kaggle/input/ai-paradox/train/abnormal/000053.wav\n/kaggle/input/ai-paradox/train/abnormal/000079.wav\n/kaggle/input/ai-paradox/train/abnormal/000085.wav\n/kaggle/input/ai-paradox/train/abnormal/000112.wav\n/kaggle/input/ai-paradox/train/abnormal/000038.wav\n/kaggle/input/ai-paradox/train/abnormal/000090.wav\n/kaggle/input/ai-paradox/train/abnormal/000074.wav\n/kaggle/input/ai-paradox/train/abnormal/000045.wav\n/kaggle/input/ai-paradox/train/abnormal/000120.wav\n/kaggle/input/ai-paradox/train/abnormal/000091.wav\n/kaggle/input/ai-paradox/train/abnormal/000052.wav\n/kaggle/input/ai-paradox/train/abnormal/000119.wav\n/kaggle/input/ai-paradox/train/abnormal/000124.wav\n/kaggle/input/ai-paradox/train/abnormal/000010.wav\n/kaggle/input/ai-paradox/train/abnormal/000104.wav\n/kaggle/input/ai-paradox/train/abnormal/000114.wav\n/kaggle/input/ai-paradox/train/abnormal/000049.wav\n/kaggle/input/ai-paradox/train/abnormal/000007.wav\n/kaggle/input/ai-paradox/train/abnormal/000054.wav\n/kaggle/input/ai-paradox/train/abnormal/000142.wav\n/kaggle/input/ai-paradox/train/abnormal/000089.wav\n/kaggle/input/ai-paradox/train/abnormal/000131.wav\n/kaggle/input/ai-paradox/train/abnormal/000093.wav\n/kaggle/input/ai-paradox/train/abnormal/000001.wav\n/kaggle/input/ai-paradox/train/abnormal/000092.wav\n/kaggle/input/ai-paradox/train/abnormal/000047.wav\n/kaggle/input/ai-paradox/train/abnormal/000020.wav\n/kaggle/input/ai-paradox/train/abnormal/000129.wav\n/kaggle/input/ai-paradox/train/abnormal/000034.wav\n/kaggle/input/ai-paradox/train/abnormal/000141.wav\n/kaggle/input/ai-paradox/train/abnormal/000019.wav\n/kaggle/input/ai-paradox/train/abnormal/000055.wav\n/kaggle/input/ai-paradox/train/abnormal/000139.wav\n/kaggle/input/ai-paradox/train/abnormal/000150.wav\n/kaggle/input/ai-paradox/train/abnormal/000018.wav\n/kaggle/input/ai-paradox/train/abnormal/000013.wav\n/kaggle/input/ai-paradox/train/abnormal/000002.wav\n/kaggle/input/ai-paradox/train/abnormal/000123.wav\n/kaggle/input/ai-paradox/train/abnormal/000149.wav\n/kaggle/input/ai-paradox/train/abnormal/000101.wav\n/kaggle/input/ai-paradox/train/abnormal/000028.wav\n/kaggle/input/ai-paradox/train/abnormal/000159.wav\n/kaggle/input/ai-paradox/train/abnormal/000145.wav\n/kaggle/input/ai-paradox/train/abnormal/000157.wav\n/kaggle/input/ai-paradox/train/abnormal/000043.wav\n/kaggle/input/ai-paradox/train/abnormal/000062.wav\n/kaggle/input/ai-paradox/train/abnormal/000068.wav\n/kaggle/input/ai-paradox/train/abnormal/000133.wav\n/kaggle/input/ai-paradox/train/abnormal/000107.wav\n/kaggle/input/ai-paradox/train/abnormal/000073.wav\n/kaggle/input/ai-paradox/train/abnormal/000153.wav\n/kaggle/input/ai-paradox/train/abnormal/000008.wav\n/kaggle/input/ai-paradox/train/abnormal/000161.wav\n/kaggle/input/ai-paradox/train/abnormal/000108.wav\n/kaggle/input/ai-paradox/train/abnormal/000122.wav\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# STEP 1: Install required packages\n!pip install catboost -q\n\nimport os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchaudio\nimport librosa\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom scipy import stats\nfrom scipy.stats import kurtosis, skew\n\n# Sklearn imports\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.metrics import roc_auc_score, accuracy_score, classification_report, f1_score\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Model imports\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Device setup\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(\"=\"*60)\nprint(\"âœ… STEP 1 COMPLETE: All imports successful\")\nprint(\"=\"*60)\nprint(f\"ğŸ”¥ Using device: {device}\")\nprint(f\"ğŸ“¦ NumPy version: {np.__version__}\")\nprint(f\"ğŸ“¦ Pandas version: {pd.__version__}\")\nprint(f\"ğŸ“¦ PyTorch version: {torch.__version__}\")\nprint(f\"ğŸ“¦ Librosa version: {librosa.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T10:14:16.520019Z","iopub.execute_input":"2025-10-15T10:14:16.520696Z","iopub.status.idle":"2025-10-15T10:14:26.628130Z","shell.execute_reply.started":"2025-10-15T10:14:16.520673Z","shell.execute_reply":"2025-10-15T10:14:26.627396Z"}},"outputs":[{"name":"stdout","text":"============================================================\nâœ… STEP 1 COMPLETE: All imports successful\n============================================================\nğŸ”¥ Using device: cuda\nğŸ“¦ NumPy version: 1.26.4\nğŸ“¦ Pandas version: 2.2.3\nğŸ“¦ PyTorch version: 2.6.0+cu124\nğŸ“¦ Librosa version: 0.11.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# STEP 2 (FIXED): Install missing dependency and load PANNs\n\n# Install torchlibrosa\nprint(\"ğŸ“¥ Installing torchlibrosa...\")\n!pip install torchlibrosa -q\n\n# Clone PANNs repository (if not already done)\nif not os.path.exists('/kaggle/working/panns_inference'):\n    print(\"\\nğŸ“¥ Cloning PANNs repository...\")\n    !git clone https://github.com/qiuqiangkong/panns_inference.git\nelse:\n    print(\"\\nâœ“ PANNs repository already cloned\")\n\nsys.path.append('/kaggle/working/panns_inference')\n\n# Download PANNs pretrained weights (if not already done)\nif not os.path.exists('Cnn14.pth'):\n    print(\"\\nğŸ“¥ Downloading PANNs CNN14 weights...\")\n    !wget -q https://zenodo.org/record/3987831/files/Cnn14_mAP%3D0.431.pth -O Cnn14.pth\nelse:\n    print(\"\\nâœ“ CNN14 weights already downloaded\")\n\n# Import and load PANNs\nprint(\"\\nğŸ”§ Loading PANNs model...\")\nfrom panns_inference import AudioTagging\n\nmodel = AudioTagging(checkpoint_path='Cnn14.pth', device=device)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… STEP 2 COMPLETE: PANNs model loaded successfully!\")\nprint(\"=\"*60)\nprint(f\"ğŸ“Š Model type: CNN14\")\nprint(f\"ğŸ“Š Device: {device}\")\nprint(f\"ğŸ“Š Embedding dimension: 2048\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T10:21:45.056079Z","iopub.execute_input":"2025-10-15T10:21:45.057006Z","iopub.status.idle":"2025-10-15T10:22:00.397398Z","shell.execute_reply.started":"2025-10-15T10:21:45.056976Z","shell.execute_reply":"2025-10-15T10:22:00.396678Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Installing torchlibrosa...\n\nâœ“ PANNs repository already cloned\n\nâœ“ CNN14 weights already downloaded\n\nğŸ”§ Loading PANNs model...\nCheckpoint path: Cnn14.pth\n","output_type":"stream"},{"name":"stderr","text":"--2025-10-15 10:21:48--  http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv\nResolving storage.googleapis.com (storage.googleapis.com)... 142.250.98.207, 108.177.12.207, 173.194.210.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.250.98.207|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 14675 (14K) [application/octet-stream]\nSaving to: â€˜/root/panns_data/class_labels_indices.csvâ€™\n\n     0K .......... ....                                       100% 68.8M=0s\n\n2025-10-15 10:21:48 (68.8 MB/s) - â€˜/root/panns_data/class_labels_indices.csvâ€™ saved [14675/14675]\n\n","output_type":"stream"},{"name":"stdout","text":"Using CPU.\n\n============================================================\nâœ… STEP 2 COMPLETE: PANNs model loaded successfully!\n============================================================\nğŸ“Š Model type: CNN14\nğŸ“Š Device: cuda\nğŸ“Š Embedding dimension: 2048\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# STEP 3: Define paths and load training/test file lists\n\nprint(\"ğŸ“‚ Setting up data paths...\")\n\n# Define base paths\nBASE_PATH = '/kaggle/input/ai-paradox'\nTRAIN_NORMAL = os.path.join(BASE_PATH, 'train/normal')\nTRAIN_ABNORMAL = os.path.join(BASE_PATH, 'train/abnormal')\nTEST_PATH = os.path.join(BASE_PATH, 'test')\n\n# Verify paths exist\nprint(\"\\nğŸ” Verifying paths...\")\nfor path_name, path in [('Train/Normal', TRAIN_NORMAL), \n                         ('Train/Abnormal', TRAIN_ABNORMAL), \n                         ('Test', TEST_PATH)]:\n    if os.path.exists(path):\n        print(f\"   âœ“ {path_name}: {path}\")\n    else:\n        print(f\"   âœ— {path_name}: NOT FOUND\")\n\n# Get training files\nprint(\"\\nğŸ“¥ Loading file lists...\")\nnormal_files = sorted([os.path.join(TRAIN_NORMAL, f) \n                       for f in os.listdir(TRAIN_NORMAL) \n                       if f.endswith('.wav')])\nabnormal_files = sorted([os.path.join(TRAIN_ABNORMAL, f) \n                         for f in os.listdir(TRAIN_ABNORMAL) \n                         if f.endswith('.wav')])\n\n# Combine training files and create labels\ntrain_files = normal_files + abnormal_files\ntrain_labels = [0] * len(normal_files) + [1] * len(abnormal_files)\n\n# Get test files\ntest_files = sorted([os.path.join(TEST_PATH, f) \n                     for f in os.listdir(TEST_PATH) \n                     if f.endswith('.wav')])\n\n# Summary\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… STEP 3 COMPLETE: Data paths configured\")\nprint(\"=\"*60)\nprint(f\"ğŸ“Š Dataset Summary:\")\nprint(f\"   Normal files: {len(normal_files)}\")\nprint(f\"   Abnormal files: {len(abnormal_files)}\")\nprint(f\"   Total training: {len(train_files)}\")\nprint(f\"   Test files: {len(test_files)}\")\nprint(f\"   Class balance: {len(abnormal_files)/len(train_files)*100:.1f}% abnormal\")\nprint(f\"\\nğŸ“ Example files:\")\nprint(f\"   Normal: {os.path.basename(normal_files[0])}\")\nprint(f\"   Abnormal: {os.path.basename(abnormal_files[0])}\")\nprint(f\"   Test: {os.path.basename(test_files[0])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T10:23:43.924587Z","iopub.execute_input":"2025-10-15T10:23:43.924876Z","iopub.status.idle":"2025-10-15T10:23:43.937123Z","shell.execute_reply.started":"2025-10-15T10:23:43.924855Z","shell.execute_reply":"2025-10-15T10:23:43.936406Z"}},"outputs":[{"name":"stdout","text":"ğŸ“‚ Setting up data paths...\n\nğŸ” Verifying paths...\n   âœ“ Train/Normal: /kaggle/input/ai-paradox/train/normal\n   âœ“ Train/Abnormal: /kaggle/input/ai-paradox/train/abnormal\n   âœ“ Test: /kaggle/input/ai-paradox/test\n\nğŸ“¥ Loading file lists...\n\n============================================================\nâœ… STEP 3 COMPLETE: Data paths configured\n============================================================\nğŸ“Š Dataset Summary:\n   Normal files: 457\n   Abnormal files: 165\n   Total training: 622\n   Test files: 156\n   Class balance: 26.5% abnormal\n\nğŸ“ Example files:\n   Normal: 000001.wav\n   Abnormal: 000001.wav\n   Test: 00001.wav\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# STEP 4: Define all feature extraction functions\n\nprint(\"ğŸ”§ Defining feature extraction functions...\")\n\n# ===== Function 1: Load audio for PANNs (32kHz) =====\ndef load_audio_for_panns(file_path, target_sr=32000):\n    \"\"\"Load audio for PANNs at 32kHz\"\"\"\n    try:\n        audio, sr = librosa.load(file_path, sr=target_sr, mono=True)\n        audio_tensor = torch.from_numpy(audio).float()\n        return audio_tensor\n    except Exception as e:\n        print(f\"âŒ Error loading {file_path}: {e}\")\n        return None\n\n\n# ===== Function 2: Extract 253 advanced audio features =====\ndef extract_advanced_audio_features(file_path, sr=22050):\n    \"\"\"\n    Extract 253 comprehensive audio features\n    Based on YAMNet approach\n    \"\"\"\n    try:\n        # Load audio at 22050 Hz for librosa features\n        y, _ = librosa.load(file_path, sr=sr, duration=5, mono=True)\n        \n        # Pad or truncate to consistent length (5 seconds)\n        max_len = sr * 5\n        if len(y) < max_len:\n            y = np.pad(y, (0, max_len - len(y)), 'constant')\n        else:\n            y = y[:max_len]\n        \n        features = []\n        \n        # 1. Statistical features (9)\n        features.extend([\n            np.mean(y), np.std(y), np.max(y), np.min(y),\n            np.median(y), kurtosis(y), skew(y),\n            np.percentile(y, 25), np.percentile(y, 75)\n        ])\n        \n        # 2. Spectral features (30)\n        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n        features.extend([np.mean(spectral_centroids), np.std(spectral_centroids)])\n        \n        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n        features.extend([np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n        \n        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n        features.extend([np.mean(spectral_bandwidth), np.std(spectral_bandwidth)])\n        \n        spectral_flatness = librosa.feature.spectral_flatness(y=y)[0]\n        features.extend([np.mean(spectral_flatness), np.std(spectral_flatness)])\n        \n        spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n        features.extend(np.mean(spectral_contrast, axis=1))\n        features.extend(np.std(spectral_contrast, axis=1))\n        \n        rolloff_85 = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.85)[0]\n        rolloff_95 = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.95)[0]\n        features.extend([np.mean(rolloff_85), np.mean(rolloff_95)])\n        \n        # 3. MFCC features (120)\n        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n        mfcc_delta = librosa.feature.delta(mfccs)\n        mfcc_delta2 = librosa.feature.delta(mfccs, order=2)\n        \n        for mfcc_matrix in [mfccs, mfcc_delta, mfcc_delta2]:\n            features.extend(np.mean(mfcc_matrix, axis=1))\n            features.extend(np.std(mfcc_matrix, axis=1))\n        \n        # 4. Temporal features (6)\n        zcr = librosa.feature.zero_crossing_rate(y)[0]\n        features.extend([np.mean(zcr), np.std(zcr), np.max(zcr)])\n        \n        rms = librosa.feature.rms(y=y)[0]\n        features.extend([np.mean(rms), np.std(rms), np.max(rms)])\n        \n        # 5. Chroma features (72)\n        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n        features.extend(np.mean(chroma_stft, axis=1))\n        features.extend(np.std(chroma_stft, axis=1))\n        \n        chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n        features.extend(np.mean(chroma_cqt, axis=1))\n        features.extend(np.std(chroma_cqt, axis=1))\n        \n        chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n        features.extend(np.mean(chroma_cens, axis=1))\n        features.extend(np.std(chroma_cens, axis=1))\n        \n        # 6. Mel-spectrogram (4)\n        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64)\n        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n        features.extend([\n            np.mean(mel_spec_db), np.std(mel_spec_db),\n            np.max(mel_spec_db), np.min(mel_spec_db)\n        ])\n        \n        # 7. Tonnetz (12)\n        harmonic = librosa.effects.harmonic(y)\n        tonnetz = librosa.feature.tonnetz(y=harmonic, sr=sr)\n        features.extend(np.mean(tonnetz, axis=1))\n        features.extend(np.std(tonnetz, axis=1))\n        \n        # 8. Polynomial features (4)\n        poly_features = librosa.feature.poly_features(y=y, sr=sr)\n        features.extend(np.mean(poly_features, axis=1))\n        features.extend(np.std(poly_features, axis=1))\n        \n        # 9. Tempogram (2)\n        onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n        tempogram = librosa.feature.tempogram(onset_envelope=onset_env, sr=sr)\n        features.extend([np.mean(tempogram), np.std(tempogram)])\n        \n        return np.array(features)\n        \n    except Exception as e:\n        print(f\"âŒ Error: {e}\")\n        return None\n\n\n# ===== Function 3: Extract combined features (PANNs + Audio) =====\ndef extract_combined_features(audio_files, labels=None, batch_size=16):\n    \"\"\"\n    Extract PANNs embeddings (2048) + Audio features (253)\n    Total: 2301 features per file\n    \"\"\"\n    panns_embeddings = []\n    audio_features = []\n    valid_labels = []\n    valid_files = []\n    skipped = []\n    \n    print(f\"ğŸµ Extracting combined features from {len(audio_files)} files...\")\n    \n    for i in tqdm(range(0, len(audio_files), batch_size)):\n        batch_files = audio_files[i:i+batch_size]\n        batch_labels = labels[i:i+batch_size] if labels is not None else [None]*len(batch_files)\n        \n        for file_path, label in zip(batch_files, batch_labels):\n            # Extract PANNs embedding\n            audio = load_audio_for_panns(file_path)\n            if audio is None:\n                skipped.append(file_path)\n                continue\n            \n            audio_tensor = audio.unsqueeze(0).to(device)\n            with torch.no_grad():\n                output = model.inference(audio_tensor)\n                panns_emb = output[1] if isinstance(output, tuple) else output\n                if isinstance(panns_emb, torch.Tensor):\n                    panns_emb = panns_emb.cpu().numpy()\n                panns_emb = np.squeeze(panns_emb)\n            \n            # Extract audio features\n            audio_feat = extract_advanced_audio_features(file_path)\n            if audio_feat is None:\n                skipped.append(file_path)\n                continue\n            \n            panns_embeddings.append(panns_emb)\n            audio_features.append(audio_feat)\n            valid_files.append(os.path.basename(file_path))\n            if label is not None:\n                valid_labels.append(label)\n    \n    panns_embeddings = np.array(panns_embeddings)\n    audio_features = np.array(audio_features)\n    combined = np.hstack([panns_embeddings, audio_features])\n    \n    if skipped:\n        print(f\"âš ï¸ Skipped {len(skipped)} files\")\n    \n    print(f\"âœ… PANNs embeddings: {panns_embeddings.shape}\")\n    print(f\"âœ… Audio features: {audio_features.shape}\")\n    print(f\"âœ… Combined features: {combined.shape}\")\n    \n    return combined, valid_labels if labels is not None else None, valid_files\n\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… STEP 4 COMPLETE: Feature extraction functions defined\")\nprint(\"=\"*60)\nprint(\"ğŸ“Š Functions ready:\")\nprint(\"   â€¢ load_audio_for_panns() - Loads audio at 32kHz for PANNs\")\nprint(\"   â€¢ extract_advanced_audio_features() - Extracts 253 features\")\nprint(\"   â€¢ extract_combined_features() - Combines PANNs + audio features\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T10:25:47.183615Z","iopub.execute_input":"2025-10-15T10:25:47.183887Z","iopub.status.idle":"2025-10-15T10:25:47.204969Z","shell.execute_reply.started":"2025-10-15T10:25:47.183869Z","shell.execute_reply":"2025-10-15T10:25:47.204335Z"}},"outputs":[{"name":"stdout","text":"ğŸ”§ Defining feature extraction functions...\n\n============================================================\nâœ… STEP 4 COMPLETE: Feature extraction functions defined\n============================================================\nğŸ“Š Functions ready:\n   â€¢ load_audio_for_panns() - Loads audio at 32kHz for PANNs\n   â€¢ extract_advanced_audio_features() - Extracts 253 features\n   â€¢ extract_combined_features() - Combines PANNs + audio features\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# STEP 5: Define preprocessing functions\n\nprint(\"ğŸ”§ Defining preprocessing functions...\")\n\n# ===== Custom SMOTE Implementation =====\nclass SimpleSMOTE:\n    \"\"\"Custom SMOTE - handles class imbalance\"\"\"\n    def __init__(self, k_neighbors=3, random_state=42):\n        self.k_neighbors = k_neighbors\n        self.random_state = random_state\n        \n    def fit_resample(self, X, y):\n        np.random.seed(self.random_state)\n        \n        # Separate majority and minority classes\n        X_maj = X[y == 0]\n        X_min = X[y == 1]\n        y_maj = y[y == 0]\n        y_min = y[y == 1]\n        \n        # Calculate how many synthetic samples needed\n        n_samples_needed = len(X_maj) - len(X_min)\n        \n        if n_samples_needed <= 0:\n            return X, y\n        \n        # Fit nearest neighbors on minority class\n        k = min(self.k_neighbors + 1, len(X_min))\n        nn = NearestNeighbors(n_neighbors=k)\n        nn.fit(X_min)\n        \n        # Generate synthetic samples\n        synthetic_samples = []\n        for _ in range(n_samples_needed):\n            idx = np.random.randint(0, len(X_min))\n            sample = X_min[idx]\n            neighbors_idx = nn.kneighbors([sample], return_distance=False)[0][1:]\n            \n            if len(neighbors_idx) > 0:\n                neighbor_idx = np.random.choice(neighbors_idx)\n                neighbor = X_min[neighbor_idx]\n                alpha = np.random.random()\n                synthetic = sample + alpha * (neighbor - sample)\n                synthetic_samples.append(synthetic)\n        \n        # Combine all samples\n        if len(synthetic_samples) > 0:\n            X_synthetic = np.array(synthetic_samples)\n            y_synthetic = np.ones(len(X_synthetic), dtype=int)\n            X_balanced = np.vstack([X_maj, X_min, X_synthetic])\n            y_balanced = np.hstack([y_maj, y_min, y_synthetic])\n        else:\n            X_balanced = np.vstack([X_maj, X_min])\n            y_balanced = np.hstack([y_maj, y_min])\n        \n        # Shuffle\n        shuffle_idx = np.random.permutation(len(X_balanced))\n        return X_balanced[shuffle_idx], y_balanced[shuffle_idx]\n\n\n# ===== Preprocessing Pipeline =====\ndef preprocess_features(X_train, y_train, X_val=None):\n    \"\"\"\n    Complete preprocessing pipeline:\n    1. Clean data (NaN, inf)\n    2. Remove low-variance features\n    3. Robust scaling\n    4. SMOTE balancing\n    \"\"\"\n    print(\"\\nğŸ”§ PREPROCESSING PIPELINE\")\n    print(\"=\"*60)\n    \n    # Step 1: Clean data\n    print(\"   Step 1: Cleaning data...\")\n    X_train = np.nan_to_num(X_train)\n    X_train = np.clip(X_train, -1e10, 1e10)\n    print(f\"      âœ“ Removed NaN/Inf values\")\n    \n    # Step 2: Variance threshold\n    print(\"   Step 2: Removing low-variance features...\")\n    var_thresh = VarianceThreshold(threshold=0.001)\n    X_train_filtered = var_thresh.fit_transform(X_train)\n    removed = X_train.shape[1] - X_train_filtered.shape[1]\n    print(f\"      âœ“ Removed {removed} low-variance features\")\n    print(f\"      âœ“ Remaining: {X_train_filtered.shape[1]} features\")\n    \n    # Step 3: Robust scaling\n    print(\"   Step 3: Scaling features...\")\n    scaler = RobustScaler()\n    X_train_scaled = scaler.fit_transform(X_train_filtered)\n    print(f\"      âœ“ Features scaled with RobustScaler\")\n    \n    # Step 4: SMOTE\n    print(\"   Step 4: Balancing classes with SMOTE...\")\n    print(f\"      Before: Normal={np.sum(y_train==0)}, Abnormal={np.sum(y_train==1)}\")\n    smote = SimpleSMOTE(k_neighbors=3, random_state=42)\n    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n    print(f\"      After:  Normal={np.sum(y_train_balanced==0)}, Abnormal={np.sum(y_train_balanced==1)}\")\n    print(f\"      âœ“ Generated {len(y_train_balanced) - len(y_train)} synthetic samples\")\n    \n    # Process validation set if provided\n    if X_val is not None:\n        X_val = np.nan_to_num(X_val)\n        X_val = np.clip(X_val, -1e10, 1e10)\n        X_val_filtered = var_thresh.transform(X_val)\n        X_val_scaled = scaler.transform(X_val_filtered)\n        print(f\"\\n   âœ“ Validation set preprocessed: {X_val_scaled.shape}\")\n        return X_train_balanced, y_train_balanced, X_val_scaled, var_thresh, scaler\n    \n    return X_train_balanced, y_train_balanced, None, var_thresh, scaler\n\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… STEP 5 COMPLETE: Preprocessing functions defined\")\nprint(\"=\"*60)\nprint(\"ğŸ“Š Components ready:\")\nprint(\"   â€¢ SimpleSMOTE class - Synthetic oversampling\")\nprint(\"   â€¢ preprocess_features() - Complete preprocessing pipeline\")\nprint(\"   â€¢ VarianceThreshold - Removes useless features\")\nprint(\"   â€¢ RobustScaler - Handles outliers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T10:27:03.641275Z","iopub.execute_input":"2025-10-15T10:27:03.641522Z","iopub.status.idle":"2025-10-15T10:27:03.653995Z","shell.execute_reply.started":"2025-10-15T10:27:03.641506Z","shell.execute_reply":"2025-10-15T10:27:03.653344Z"}},"outputs":[{"name":"stdout","text":"ğŸ”§ Defining preprocessing functions...\n\n============================================================\nâœ… STEP 5 COMPLETE: Preprocessing functions defined\n============================================================\nğŸ“Š Components ready:\n   â€¢ SimpleSMOTE class - Synthetic oversampling\n   â€¢ preprocess_features() - Complete preprocessing pipeline\n   â€¢ VarianceThreshold - Removes useless features\n   â€¢ RobustScaler - Handles outliers\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# STEP 6: Define model training and ensemble functions\n\nprint(\"ğŸ”§ Defining model training functions...\")\n\n\n# ===== Train 4 Optimized Models =====\ndef train_optimized_models(X_train, y_train, X_val, y_val):\n    \"\"\"\n    Train 4 models: CatBoost, XGBoost, RandomForest, ExtraTrees\n    \"\"\"\n    models = {}\n    scores = {}\n    \n    # Calculate class weights\n    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n    scale_pos_weight = class_weights[1] / class_weights[0]\n    \n    print(\"\\nğŸš€ TRAINING OPTIMIZED MODELS\")\n    print(\"=\"*60)\n    print(f\"   Class weight ratio: {scale_pos_weight:.2f}\")\n    \n    # 1. CatBoost\n    print(\"\\n1ï¸âƒ£ Training CatBoost...\")\n    cat_model = CatBoostClassifier(\n        iterations=2000,\n        learning_rate=0.05,\n        depth=10,\n        l2_leaf_reg=5,\n        random_seed=42,\n        verbose=0,\n        early_stopping_rounds=100,\n        class_weights=[1.0, 2.0]\n    )\n    cat_model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)\n    \n    y_pred_cat = cat_model.predict(X_val)\n    y_proba_cat = cat_model.predict_proba(X_val)[:, 1]\n    auc_cat = roc_auc_score(y_val, y_proba_cat)\n    acc_cat = accuracy_score(y_val, y_pred_cat)\n    \n    models['CatBoost'] = cat_model\n    scores['CatBoost'] = {'auc': auc_cat, 'acc': acc_cat, 'proba': y_proba_cat}\n    print(f\"   âœ… AUC: {auc_cat:.4f} | Accuracy: {acc_cat:.4f}\")\n    \n    # 2. XGBoost\n    print(\"\\n2ï¸âƒ£ Training XGBoost...\")\n    xgb_model = xgb.XGBClassifier(\n        n_estimators=2000,\n        max_depth=10,\n        learning_rate=0.05,\n        reg_alpha=0.2,\n        reg_lambda=0.2,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        random_state=42,\n        scale_pos_weight=2.0,\n        eval_metric='logloss',\n        early_stopping_rounds=100\n    )\n    xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n    \n    y_pred_xgb = xgb_model.predict(X_val)\n    y_proba_xgb = xgb_model.predict_proba(X_val)[:, 1]\n    auc_xgb = roc_auc_score(y_val, y_proba_xgb)\n    acc_xgb = accuracy_score(y_val, y_pred_xgb)\n    \n    models['XGBoost'] = xgb_model\n    scores['XGBoost'] = {'auc': auc_xgb, 'acc': acc_xgb, 'proba': y_proba_xgb}\n    print(f\"   âœ… AUC: {auc_xgb:.4f} | Accuracy: {acc_xgb:.4f}\")\n    \n    # 3. Random Forest\n    print(\"\\n3ï¸âƒ£ Training Random Forest...\")\n    rf_model = RandomForestClassifier(\n        n_estimators=500,\n        max_depth=15,\n        min_samples_split=5,\n        min_samples_leaf=2,\n        random_state=42,\n        n_jobs=-1,\n        class_weight='balanced'\n    )\n    rf_model.fit(X_train, y_train)\n    \n    y_pred_rf = rf_model.predict(X_val)\n    y_proba_rf = rf_model.predict_proba(X_val)[:, 1]\n    auc_rf = roc_auc_score(y_val, y_proba_rf)\n    acc_rf = accuracy_score(y_val, y_pred_rf)\n    \n    models['RandomForest'] = rf_model\n    scores['RandomForest'] = {'auc': auc_rf, 'acc': acc_rf, 'proba': y_proba_rf}\n    print(f\"   âœ… AUC: {auc_rf:.4f} | Accuracy: {acc_rf:.4f}\")\n    \n    # 4. Extra Trees\n    print(\"\\n4ï¸âƒ£ Training Extra Trees...\")\n    et_model = ExtraTreesClassifier(\n        n_estimators=500,\n        max_depth=15,\n        min_samples_split=5,\n        min_samples_leaf=2,\n        random_state=42,\n        n_jobs=-1,\n        class_weight='balanced'\n    )\n    et_model.fit(X_train, y_train)\n    \n    y_pred_et = et_model.predict(X_val)\n    y_proba_et = et_model.predict_proba(X_val)[:, 1]\n    auc_et = roc_auc_score(y_val, y_proba_et)\n    acc_et = accuracy_score(y_val, y_pred_et)\n    \n    models['ExtraTrees'] = et_model\n    scores['ExtraTrees'] = {'auc': auc_et, 'acc': acc_et, 'proba': y_proba_et}\n    print(f\"   âœ… AUC: {auc_et:.4f} | Accuracy: {acc_et:.4f}\")\n    \n    return models, scores\n\n\n# ===== Create Weighted Ensemble with Threshold Optimization =====\ndef create_optimized_ensemble(models, scores, X_val, y_val):\n    \"\"\"\n    Create weighted ensemble using F1 scores\n    Optimize threshold for best F1\n    \"\"\"\n    print(\"\\nğŸ”® CREATING WEIGHTED ENSEMBLE\")\n    print(\"=\"*60)\n    \n    model_weights = {}\n    \n    # Calculate F1-based weights\n    print(\"\\nğŸ“Š Calculating model weights based on F1 scores...\")\n    for name in models.keys():\n        best_f1 = 0\n        for threshold in np.arange(0.2, 0.8, 0.01):\n            y_pred = (scores[name]['proba'] > threshold).astype(int)\n            f1 = f1_score(y_val, y_pred)\n            if f1 > best_f1:\n                best_f1 = f1\n        \n        model_weights[name] = best_f1\n        print(f\"   {name}: F1 = {best_f1:.4f}\")\n    \n    # Normalize weights\n    total_weight = sum(model_weights.values())\n    for name in model_weights:\n        model_weights[name] /= total_weight\n    \n    print(f\"\\nğŸ“Š Normalized model weights:\")\n    for name, weight in model_weights.items():\n        print(f\"   {name}: {weight:.4f}\")\n    \n    # Create ensemble predictions\n    ensemble_proba = np.zeros(len(y_val))\n    for name, weight in model_weights.items():\n        ensemble_proba += weight * scores[name]['proba']\n    \n    # Optimize threshold\n    print(f\"\\nğŸ¯ Optimizing threshold...\")\n    best_threshold = 0.5\n    best_f1 = 0\n    \n    for threshold in np.arange(0.2, 0.8, 0.005):\n        y_pred = (ensemble_proba > threshold).astype(int)\n        f1 = f1_score(y_val, y_pred)\n        if f1 > best_f1:\n            best_f1 = f1\n            best_threshold = threshold\n    \n    ensemble_pred = (ensemble_proba >= best_threshold).astype(int)\n    auc_ensemble = roc_auc_score(y_val, ensemble_proba)\n    acc_ensemble = accuracy_score(y_val, ensemble_pred)\n    \n    print(f\"\\nâœ… Ensemble Performance:\")\n    print(f\"   Optimal Threshold: {best_threshold:.3f}\")\n    print(f\"   Best F1 Score: {best_f1:.4f}\")\n    print(f\"   AUC-ROC: {auc_ensemble:.4f}\")\n    print(f\"   Accuracy: {acc_ensemble:.4f}\")\n    \n    print(f\"\\nğŸ“‹ Classification Report:\")\n    print(classification_report(y_val, ensemble_pred, target_names=['Normal', 'Abnormal']))\n    \n    return model_weights, best_threshold, best_f1\n\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… STEP 6 COMPLETE: Model training functions defined\")\nprint(\"=\"*60)\nprint(\"ğŸ“Š Functions ready:\")\nprint(\"   â€¢ train_optimized_models() - Trains 4 models with early stopping\")\nprint(\"   â€¢ create_optimized_ensemble() - F1-weighted ensemble with threshold opt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T10:29:03.682770Z","iopub.execute_input":"2025-10-15T10:29:03.682972Z","iopub.status.idle":"2025-10-15T10:29:03.698920Z","shell.execute_reply.started":"2025-10-15T10:29:03.682957Z","shell.execute_reply":"2025-10-15T10:29:03.698253Z"}},"outputs":[{"name":"stdout","text":"ğŸ”§ Defining model training functions...\n\n============================================================\nâœ… STEP 6 COMPLETE: Model training functions defined\n============================================================\nğŸ“Š Functions ready:\n   â€¢ train_optimized_models() - Trains 4 models with early stopping\n   â€¢ create_optimized_ensemble() - F1-weighted ensemble with threshold opt\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# STEP 7: Extract combined features from training data\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸ¬ STARTING FEATURE EXTRACTION - TRAINING DATA\")\nprint(\"=\"*60)\nprint(f\"ğŸ“Š Files to process: {len(train_files)}\")\nprint(f\"â±ï¸  Estimated time: 10-15 minutes\")\nprint(f\"ğŸ”§ Batch size: 16\")\nprint(\"\\nğŸš€ Starting extraction...\\n\")\n\n# Extract features\ntrain_features, train_labels_valid, _ = extract_combined_features(\n    train_files,\n    train_labels,\n    batch_size=16\n)\n\n# Convert labels to numpy array\ny_train_full = np.array(train_labels_valid)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… STEP 7 COMPLETE: Training features extracted\")\nprint(\"=\"*60)\nprint(f\"ğŸ“Š Feature matrix shape: {train_features.shape}\")\nprint(f\"ğŸ“Š Labels shape: {y_train_full.shape}\")\nprint(f\"ğŸ“Š Features per sample: {train_features.shape[1]}\")\nprint(f\"   - PANNs embeddings: 2048\")\nprint(f\"   - Audio features: {train_features.shape[1] - 2048}\")\nprint(f\"\\nğŸ“Š Label distribution:\")\nprint(f\"   Normal (0): {np.sum(y_train_full==0)} samples\")\nprint(f\"   Abnormal (1): {np.sum(y_train_full==1)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T10:30:50.496522Z","iopub.execute_input":"2025-10-15T10:30:50.496844Z","iopub.status.idle":"2025-10-15T10:42:52.269083Z","shell.execute_reply.started":"2025-10-15T10:30:50.496823Z","shell.execute_reply":"2025-10-15T10:42:52.268318Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸ¬ STARTING FEATURE EXTRACTION - TRAINING DATA\n============================================================\nğŸ“Š Files to process: 622\nâ±ï¸  Estimated time: 10-15 minutes\nğŸ”§ Batch size: 16\n\nğŸš€ Starting extraction...\n\nğŸµ Extracting combined features from 622 files...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [12:01<00:00, 18.51s/it]","output_type":"stream"},{"name":"stdout","text":"âœ… PANNs embeddings: (622, 2048)\nâœ… Audio features: (622, 253)\nâœ… Combined features: (622, 2301)\n\n============================================================\nâœ… STEP 7 COMPLETE: Training features extracted\n============================================================\nğŸ“Š Feature matrix shape: (622, 2301)\nğŸ“Š Labels shape: (622,)\nğŸ“Š Features per sample: 2301\n   - PANNs embeddings: 2048\n   - Audio features: 253\n\nğŸ“Š Label distribution:\n   Normal (0): 457 samples\n   Abnormal (1): 165 samples\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# STEP 8: Train/Validation split and preprocessing\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸ“Š STEP 8: TRAIN/VALIDATION SPLIT & PREPROCESSING\")\nprint(\"=\"*60)\n\n# Split into train and validation (85/15 like YAMNet approach)\nprint(\"\\nğŸ”€ Splitting data (85% train, 15% validation)...\")\nX_train_raw, X_val_raw, y_train, y_val = train_test_split(\n    train_features,\n    y_train_full,\n    test_size=0.15,\n    random_state=42,\n    stratify=y_train_full\n)\n\nprint(f\"   Train set: {X_train_raw.shape}\")\nprint(f\"   Val set: {X_val_raw.shape}\")\nprint(f\"   Train labels: Normal={np.sum(y_train==0)}, Abnormal={np.sum(y_train==1)}\")\nprint(f\"   Val labels: Normal={np.sum(y_val==0)}, Abnormal={np.sum(y_val==1)}\")\n\n# Apply preprocessing pipeline\nX_train, y_train_balanced, X_val, var_thresh, scaler = preprocess_features(\n    X_train_raw, y_train, X_val_raw\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… STEP 8 COMPLETE: Data split and preprocessed\")\nprint(\"=\"*60)\nprint(f\"ğŸ“Š Final shapes:\")\nprint(f\"   Train (balanced): {X_train.shape}\")\nprint(f\"   Train labels (balanced): {y_train_balanced.shape}\")\nprint(f\"   Validation: {X_val.shape}\")\nprint(f\"   Validation labels: {y_val.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T10:45:46.413946Z","iopub.execute_input":"2025-10-15T10:45:46.414300Z","iopub.status.idle":"2025-10-15T10:45:46.812838Z","shell.execute_reply.started":"2025-10-15T10:45:46.414265Z","shell.execute_reply":"2025-10-15T10:45:46.812110Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸ“Š STEP 8: TRAIN/VALIDATION SPLIT & PREPROCESSING\n============================================================\n\nğŸ”€ Splitting data (85% train, 15% validation)...\n   Train set: (528, 2301)\n   Val set: (94, 2301)\n   Train labels: Normal=388, Abnormal=140\n   Val labels: Normal=69, Abnormal=25\n\nğŸ”§ PREPROCESSING PIPELINE\n============================================================\n   Step 1: Cleaning data...\n      âœ“ Removed NaN/Inf values\n   Step 2: Removing low-variance features...\n      âœ“ Removed 1637 low-variance features\n      âœ“ Remaining: 664 features\n   Step 3: Scaling features...\n      âœ“ Features scaled with RobustScaler\n   Step 4: Balancing classes with SMOTE...\n      Before: Normal=388, Abnormal=140\n      After:  Normal=388, Abnormal=388\n      âœ“ Generated 248 synthetic samples\n\n   âœ“ Validation set preprocessed: (94, 664)\n\n============================================================\nâœ… STEP 8 COMPLETE: Data split and preprocessed\n============================================================\nğŸ“Š Final shapes:\n   Train (balanced): (776, 664)\n   Train labels (balanced): (776,)\n   Validation: (94, 664)\n   Validation labels: (94,)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# STEP 9: Train all 4 optimized models\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸš€ STEP 9: TRAINING ALL MODELS\")\nprint(\"=\"*60)\nprint(f\"ğŸ“Š Training on {X_train.shape[0]} samples\")\nprint(f\"ğŸ“Š Validating on {X_val.shape[0]} samples\")\nprint(f\"â±ï¸  Estimated time: 5-10 minutes\")\nprint(\"\\nğŸ¯ Starting training...\\n\")\n\n# Train all 4 models\nmodels, scores = train_optimized_models(X_train, y_train_balanced, X_val, y_val)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… STEP 9 COMPLETE: All models trained\")\nprint(\"=\"*60)\nprint(\"\\nğŸ“Š Model Performance Summary:\")\nprint(\"-\" * 60)\nfor name in models.keys():\n    print(f\"{name:15} | AUC: {scores[name]['auc']:.4f} | Acc: {scores[name]['acc']:.4f}\")\nprint(\"-\" * 60)\n\n# Find best individual model\nbest_model_name = max(scores.keys(), key=lambda x: scores[x]['auc'])\nbest_auc = scores[best_model_name]['auc']\nprint(f\"\\nğŸ† Best individual model: {best_model_name} (AUC: {best_auc:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T10:48:11.850365Z","iopub.execute_input":"2025-10-15T10:48:11.851045Z","iopub.status.idle":"2025-10-15T11:08:33.200779Z","shell.execute_reply.started":"2025-10-15T10:48:11.851022Z","shell.execute_reply":"2025-10-15T11:08:33.200041Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸš€ STEP 9: TRAINING ALL MODELS\n============================================================\nğŸ“Š Training on 776 samples\nğŸ“Š Validating on 94 samples\nâ±ï¸  Estimated time: 5-10 minutes\n\nğŸ¯ Starting training...\n\n\nğŸš€ TRAINING OPTIMIZED MODELS\n============================================================\n   Class weight ratio: 1.00\n\n1ï¸âƒ£ Training CatBoost...\n   âœ… AUC: 0.9965 | Accuracy: 0.9681\n\n2ï¸âƒ£ Training XGBoost...\n   âœ… AUC: 0.9901 | Accuracy: 0.9574\n\n3ï¸âƒ£ Training Random Forest...\n   âœ… AUC: 0.9861 | Accuracy: 0.9362\n\n4ï¸âƒ£ Training Extra Trees...\n   âœ… AUC: 0.9768 | Accuracy: 0.8936\n\n============================================================\nâœ… STEP 9 COMPLETE: All models trained\n============================================================\n\nğŸ“Š Model Performance Summary:\n------------------------------------------------------------\nCatBoost        | AUC: 0.9965 | Acc: 0.9681\nXGBoost         | AUC: 0.9901 | Acc: 0.9574\nRandomForest    | AUC: 0.9861 | Acc: 0.9362\nExtraTrees      | AUC: 0.9768 | Acc: 0.8936\n------------------------------------------------------------\n\nğŸ† Best individual model: CatBoost (AUC: 0.9965)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# STEP 10: Create weighted ensemble with threshold optimization\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸ”® STEP 10: CREATING WEIGHTED ENSEMBLE\")\nprint(\"=\"*60)\nprint(\"ğŸ¯ Combining all 4 models with F1-weighted voting...\")\nprint(\"ğŸ¯ Optimizing classification threshold...\\n\")\n\n# Create ensemble\nmodel_weights, best_threshold, best_f1 = create_optimized_ensemble(\n    models, scores, X_val, y_val\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… STEP 10 COMPLETE: Ensemble created and optimized\")\nprint(\"=\"*60)\n\n# Compare individual vs ensemble\nprint(\"\\nğŸ“Š FINAL COMPARISON:\")\nprint(\"=\"*60)\nprint(\"Individual Models:\")\nfor name in models.keys():\n    print(f\"  {name:15} | AUC: {scores[name]['auc']:.4f}\")\nprint(\"\\nğŸ”® Weighted Ensemble:\")\nensemble_proba = np.zeros(len(y_val))\nfor name, weight in model_weights.items():\n    ensemble_proba += weight * scores[name]['proba']\nensemble_auc = roc_auc_score(y_val, ensemble_proba)\nprint(f\"  Ensemble        | AUC: {ensemble_auc:.4f}\")\nprint(\"=\"*60)\n\nif ensemble_auc > max([scores[name]['auc'] for name in scores.keys()]):\n    improvement = ensemble_auc - max([scores[name]['auc'] for name in scores.keys()])\n    print(f\"\\nğŸ‰ Ensemble improved by {improvement:.4f} points!\")\nelse:\n    print(f\"\\nğŸ’¡ Best individual model (CatBoost) still leads!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T11:10:56.400245Z","iopub.execute_input":"2025-10-15T11:10:56.400962Z","iopub.status.idle":"2025-10-15T11:10:56.749424Z","shell.execute_reply.started":"2025-10-15T11:10:56.400940Z","shell.execute_reply":"2025-10-15T11:10:56.748838Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸ”® STEP 10: CREATING WEIGHTED ENSEMBLE\n============================================================\nğŸ¯ Combining all 4 models with F1-weighted voting...\nğŸ¯ Optimizing classification threshold...\n\n\nğŸ”® CREATING WEIGHTED ENSEMBLE\n============================================================\n\nğŸ“Š Calculating model weights based on F1 scores...\n   CatBoost: F1 = 0.9804\n   XGBoost: F1 = 0.9200\n   RandomForest: F1 = 0.9057\n   ExtraTrees: F1 = 0.8750\n\nğŸ“Š Normalized model weights:\n   CatBoost: 0.2663\n   XGBoost: 0.2499\n   RandomForest: 0.2460\n   ExtraTrees: 0.2377\n\nğŸ¯ Optimizing threshold...\n\nâœ… Ensemble Performance:\n   Optimal Threshold: 0.350\n   Best F1 Score: 0.9434\n   AUC-ROC: 0.9925\n   Accuracy: 0.9681\n\nğŸ“‹ Classification Report:\n              precision    recall  f1-score   support\n\n      Normal       1.00      0.96      0.98        69\n    Abnormal       0.89      1.00      0.94        25\n\n    accuracy                           0.97        94\n   macro avg       0.95      0.98      0.96        94\nweighted avg       0.97      0.97      0.97        94\n\n\n============================================================\nâœ… STEP 10 COMPLETE: Ensemble created and optimized\n============================================================\n\nğŸ“Š FINAL COMPARISON:\n============================================================\nIndividual Models:\n  CatBoost        | AUC: 0.9965\n  XGBoost         | AUC: 0.9901\n  RandomForest    | AUC: 0.9861\n  ExtraTrees      | AUC: 0.9768\n\nğŸ”® Weighted Ensemble:\n  Ensemble        | AUC: 0.9925\n============================================================\n\nğŸ’¡ Best individual model (CatBoost) still leads!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# STEP 11: Retrain on full data and predict test set\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸš€ STEP 11: FINAL TRAINING & TEST PREDICTIONS\")\nprint(\"=\"*60)\n\n# Preprocess ALL training data (no split)\nprint(\"\\nğŸ”§ Preprocessing full training dataset...\")\nX_all_balanced, y_all_balanced, _, var_thresh_final, scaler_final = preprocess_features(\n    train_features, y_train_full\n)\n\nprint(f\"   Final training size: {X_all_balanced.shape}\")\n\n# Retrain CatBoost (the winner) on full dataset\nprint(\"\\nğŸ† Retraining CatBoost on full balanced dataset...\")\nfinal_model = CatBoostClassifier(\n    iterations=2000,\n    learning_rate=0.05,\n    depth=10,\n    l2_leaf_reg=5,\n    random_seed=42,\n    verbose=0,\n    class_weights=[1.0, 2.0]\n)\nfinal_model.fit(X_all_balanced, y_all_balanced)\nprint(\"   âœ… Final model trained!\")\n\n# Extract test features\nprint(\"\\nğŸµ Extracting features from test set...\")\nprint(f\"   Files to process: {len(test_files)}\")\nprint(f\"   Estimated time: 2-3 minutes\\n\")\n\ntest_features, _, test_filenames = extract_combined_features(\n    test_files,\n    labels=None,\n    batch_size=16\n)\n\n# Preprocess test data\nprint(\"\\nğŸ”§ Preprocessing test data...\")\ntest_features_clean = np.nan_to_num(test_features)\ntest_features_clean = np.clip(test_features_clean, -1e10, 1e10)\ntest_features_filtered = var_thresh_final.transform(test_features_clean)\ntest_features_scaled = scaler_final.transform(test_features_filtered)\nprint(f\"   Test features preprocessed: {test_features_scaled.shape}\")\n\n# Generate predictions\nprint(\"\\nğŸ¯ Generating predictions...\")\ntest_proba = final_model.predict_proba(test_features_scaled)[:, 1]\ntest_predictions = (test_proba >= best_threshold).astype(int)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… STEP 11 COMPLETE: Test predictions generated\")\nprint(\"=\"*60)\nprint(f\"ğŸ“Š Test Predictions:\")\nprint(f\"   Normal (0): {np.sum(test_predictions==0)} files ({np.sum(test_predictions==0)/len(test_predictions)*100:.1f}%)\")\nprint(f\"   Abnormal (1): {np.sum(test_predictions==1)} files ({np.sum(test_predictions==1)/len(test_predictions)*100:.1f}%)\")\nprint(f\"   Threshold used: {best_threshold:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T11:13:04.405008Z","iopub.execute_input":"2025-10-15T11:13:04.406012Z","iopub.status.idle":"2025-10-15T11:36:52.533361Z","shell.execute_reply.started":"2025-10-15T11:13:04.405971Z","shell.execute_reply":"2025-10-15T11:36:52.532615Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸš€ STEP 11: FINAL TRAINING & TEST PREDICTIONS\n============================================================\n\nğŸ”§ Preprocessing full training dataset...\n\nğŸ”§ PREPROCESSING PIPELINE\n============================================================\n   Step 1: Cleaning data...\n      âœ“ Removed NaN/Inf values\n   Step 2: Removing low-variance features...\n      âœ“ Removed 1638 low-variance features\n      âœ“ Remaining: 663 features\n   Step 3: Scaling features...\n      âœ“ Features scaled with RobustScaler\n   Step 4: Balancing classes with SMOTE...\n      Before: Normal=457, Abnormal=165\n      After:  Normal=457, Abnormal=457\n      âœ“ Generated 292 synthetic samples\n   Final training size: (914, 663)\n\nğŸ† Retraining CatBoost on full balanced dataset...\n   âœ… Final model trained!\n\nğŸµ Extracting features from test set...\n   Files to process: 156\n   Estimated time: 2-3 minutes\n\nğŸµ Extracting combined features from 156 files...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [03:05<00:00, 18.53s/it]","output_type":"stream"},{"name":"stdout","text":"âœ… PANNs embeddings: (156, 2048)\nâœ… Audio features: (156, 253)\nâœ… Combined features: (156, 2301)\n\nğŸ”§ Preprocessing test data...\n   Test features preprocessed: (156, 663)\n\nğŸ¯ Generating predictions...\n\n============================================================\nâœ… STEP 11 COMPLETE: Test predictions generated\n============================================================\nğŸ“Š Test Predictions:\n   Normal (0): 115 files (73.7%)\n   Abnormal (1): 41 files (26.3%)\n   Threshold used: 0.350\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# STEP 12: Create final submission CSV\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸ“ STEP 12: CREATING SUBMISSION FILE\")\nprint(\"=\"*60)\n\n# Create submission dataframe\nsubmission_df = pd.DataFrame({\n    'file_name': test_filenames,\n    'target': test_predictions\n})\n\n# Sort by filename (important for competition)\nsubmission_df = submission_df.sort_values('file_name').reset_index(drop=True)\n\n# Save submission\nsubmission_path = 'panns_advanced.csv'\nsubmission_df.to_csv(submission_path, index=False)\n\nprint(f\"\\nâœ… Submission file created: {submission_path}\")\nprint(f\"\\nğŸ“„ First 10 predictions:\")\nprint(submission_df.head(10).to_string(index=False))\nprint(f\"\\nğŸ“„ Last 10 predictions:\")\nprint(submission_df.tail(10).to_string(index=False))\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸ“Š FINAL SUBMISSION STATISTICS\")\nprint(\"=\"*60)\nprint(f\"Total files: {len(submission_df)}\")\nprint(f\"Normal predictions: {np.sum(submission_df['target']==0)} ({np.sum(submission_df['target']==0)/len(submission_df)*100:.1f}%)\")\nprint(f\"Abnormal predictions: {np.sum(submission_df['target']==1)} ({np.sum(submission_df['target']==1)/len(submission_df)*100:.1f}%)\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸŠ ALL STEPS COMPLETE!\")\nprint(\"=\"*60)\nprint(\"\\nğŸ† FINAL MODEL PERFORMANCE:\")\nprint(f\"   Model: CatBoost\")\nprint(f\"   Validation AUC-ROC: 0.9965 (99.65%)\")\nprint(f\"   Validation Accuracy: 96.81%\")\nprint(f\"   Validation F1-Score: 0.9804\")\nprint(f\"   Features used: 2301 (PANNs 2048 + Audio 253)\")\nprint(f\"   Preprocessing: VarianceThreshold + RobustScaler + SMOTE\")\nprint(f\"   Class weights: [1.0, 2.0]\")\nprint(f\"   Optimal threshold: {best_threshold:.3f}\")\n\nprint(\"\\nğŸ“¥ Download your submission file and submit to Kaggle!\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T11:42:04.908881Z","iopub.execute_input":"2025-10-15T11:42:04.909526Z","iopub.status.idle":"2025-10-15T11:42:04.969717Z","shell.execute_reply.started":"2025-10-15T11:42:04.909502Z","shell.execute_reply":"2025-10-15T11:42:04.968834Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸ“ STEP 12: CREATING SUBMISSION FILE\n============================================================\n\nâœ… Submission file created: panns_advanced.csv\n\nğŸ“„ First 10 predictions:\nfile_name  target\n00001.wav       0\n00002.wav       0\n00003.wav       0\n00004.wav       0\n00005.wav       0\n00006.wav       0\n00007.wav       0\n00008.wav       0\n00009.wav       0\n00010.wav       0\n\nğŸ“„ Last 10 predictions:\nfile_name  target\n00147.wav       1\n00148.wav       1\n00149.wav       1\n00150.wav       1\n00151.wav       1\n00152.wav       1\n00153.wav       1\n00154.wav       1\n00155.wav       1\n00156.wav       1\n\n============================================================\nğŸ“Š FINAL SUBMISSION STATISTICS\n============================================================\nTotal files: 156\nNormal predictions: 115 (73.7%)\nAbnormal predictions: 41 (26.3%)\n\n============================================================\nğŸŠ ALL STEPS COMPLETE!\n============================================================\n\nğŸ† FINAL MODEL PERFORMANCE:\n   Model: CatBoost\n   Validation AUC-ROC: 0.9965 (99.65%)\n   Validation Accuracy: 96.81%\n   Validation F1-Score: 0.9804\n   Features used: 2301 (PANNs 2048 + Audio 253)\n   Preprocessing: VarianceThreshold + RobustScaler + SMOTE\n   Class weights: [1.0, 2.0]\n   Optimal threshold: 0.350\n\nğŸ“¥ Download your submission file and submit to Kaggle!\n============================================================\n","output_type":"stream"}],"execution_count":23}]}